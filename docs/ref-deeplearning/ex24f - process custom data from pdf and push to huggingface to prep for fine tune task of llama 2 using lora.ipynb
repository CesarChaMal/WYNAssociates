{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CesarChaMal/WYNAssociates/blob/main/docs/ref-deeplearning/ex24f%20-%20process%20custom%20data%20from%20pdf%20and%20push%20to%20huggingface%20to%20prep%20for%20fine%20tune%20task%20of%20llama%202%20using%20lora.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Library"
      ],
      "metadata": {
        "id": "N1WfLHfr_oTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install openai"
      ],
      "metadata": {
        "id": "f56ySd6Al5hF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eea07d5-6779-465f-dd0d-e0ce8d7afb34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.11.1-py3-none-any.whl (226 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/226.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m225.3/226.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "2aEtlnMElIWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install datasets"
      ],
      "metadata": {
        "id": "NPA4krwVgchJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load `openassitant-guanaco` Data as Demonstration\n",
        "\n",
        "We want to understand the data format."
      ],
      "metadata": {
        "id": "C8hT_8Fz_rQs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code\n",
        "\n",
        "- **Importing `load_dataset`**: The `from datasets import load_dataset` statement imports the `load_dataset` function from the `datasets` library. This library is a part of the Hugging Face ecosystem, designed to easily share, load, and work with datasets in the machine learning field.\n",
        "\n",
        "- **Loading the Dataset**: The `load_dataset(\"timdettmers/openassistant-guanaco\")` function call tells the library to load a dataset identified by the name `timdettmers/openassistant-guanaco`. This identifier typically consists of the username or organization name (`timdettmers` in this case) and the specific dataset name (`openassistant-guanaco`)."
      ],
      "metadata": {
        "id": "0EidYGMWAACK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMx5NSwcgRJB"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"timdettmers/openassistant-guanaco\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "ZqIl5t4rgXIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"]"
      ],
      "metadata": {
        "id": "tvXxlph6gYId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"][0]"
      ],
      "metadata": {
        "id": "hUorHSXggobh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(dataset[\"train\"][0])"
      ],
      "metadata": {
        "id": "JMDmOS8rgw-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"][0].keys()"
      ],
      "metadata": {
        "id": "6mMpoXlggzNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"][1][\"text\"]"
      ],
      "metadata": {
        "id": "XueNXJrzg0Zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(dataset[\"train\"][0][\"text\"])"
      ],
      "metadata": {
        "id": "KWbjDQSog3eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset[\"train\"][0][\"text\"])"
      ],
      "metadata": {
        "id": "HeC6c3jUg7id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scrap `Any` PDF\n",
        "\n",
        "We need the `PyMuPDF` package in python. So, we install it first."
      ],
      "metadata": {
        "id": "TabtWWWmAHDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install PyMuPDF"
      ],
      "metadata": {
        "id": "_XfynWp8g8i6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `read_pdf_content` function"
      ],
      "metadata": {
        "id": "Su-PW3VLALnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "\n",
        "def read_pdf_content(pdf_path):\n",
        "    \"\"\"\n",
        "    Reads a PDF and returns its content as a list of strings.\n",
        "\n",
        "    Args:\n",
        "    pdf_path (str): The file path to the PDF.\n",
        "\n",
        "    Returns:\n",
        "    list of str: A list where each element is the text content of a PDF page.\n",
        "    \"\"\"\n",
        "    content_list = []\n",
        "    with fitz.open(pdf_path) as doc:\n",
        "        for page in doc:\n",
        "            content_list.append(page.get_text())\n",
        "\n",
        "    return content_list"
      ],
      "metadata": {
        "id": "tdjsZB5tiGQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "scraped_content = read_pdf_content(\"/content/JVM Troubleshooting Guide.pdf\")\n",
        "print(\"\\n\")\n",
        "print(scraped_content)"
      ],
      "metadata": {
        "id": "LI6rS0chiIm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(scraped_content[0])"
      ],
      "metadata": {
        "id": "UfEfXnyGiR_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scraped_content = ' '.join(scraped_content)\n",
        "print(scraped_content)"
      ],
      "metadata": {
        "id": "1otZng7aiURP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(scraped_content)"
      ],
      "metadata": {
        "id": "xonJw2x5iyUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(scraped_content)"
      ],
      "metadata": {
        "id": "F1WGELLJi6vs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scraped_content.split('. ')[0]"
      ],
      "metadata": {
        "id": "xEFsZ3jKi-cG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API Call to Create Data\n",
        "\n",
        "Here we use the `client.chat.completions.create` function from *OpenAI* as a helper function to assist us to create question answer."
      ],
      "metadata": {
        "id": "grtHYX2tAP11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = \"sk-token\"\n",
        "openai_client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "\n",
        "def call_chatgpt(query: str, model: str = \"gpt-3.5-turbo\") -> str:\n",
        "    \"\"\"\n",
        "    Generates a response to a query using the specified language model.\n",
        "    Args:\n",
        "        query (str): The user's query that needs to be processed.\n",
        "        model (str, optional): The language model to be used. Defaults to \"gpt-3.5-turbo\".\n",
        "    Returns:\n",
        "        str: The generated response to the query.\n",
        "    \"\"\"\n",
        "\n",
        "    # Prepare the conversation context with system and user messages.\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Question: {query}.\"},\n",
        "    ]\n",
        "\n",
        "    # Use the OpenAI client to generate a response based on the model and the conversation context.\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "    )\n",
        "\n",
        "    # Extract the content of the response from the first choice.\n",
        "    content: str = response.choices[0].message.content\n",
        "\n",
        "    # Return the generated content.\n",
        "    return content"
      ],
      "metadata": {
        "id": "TbimzRpTjjz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resp = call_chatgpt(\"What is the Java Heap?\")"
      ],
      "metadata": {
        "id": "pjJ5wlmOkLdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resp"
      ],
      "metadata": {
        "id": "rvHuZ-u-kGEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt Engineer\n",
        "\n",
        "We use prompt engineer to ensure the content `GPT` gave us is in the same content as the `openassist/guanaco` data.\n",
        "\n",
        "```python\n",
        "    ### Human:\n",
        "    ### Assistant:\n",
        "```"
      ],
      "metadata": {
        "id": "EXHLmEs2AfJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt_engineered_api(text: str):\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "        I have the following content: {text}\n",
        "\n",
        "        I want to create a question-answer content that has the following format:\n",
        "\n",
        "        ### Human:\n",
        "        ### Assistant:\n",
        "\n",
        "        Make sure to write question and answer based on the content I provided.\n",
        "\n",
        "        The ### Human means it's a question, and the ### Assistant means it's an answer.\n",
        "    \"\"\"\n",
        "\n",
        "    resp = call_chatgpt(prompt)\n",
        "\n",
        "    return resp"
      ],
      "metadata": {
        "id": "h_SJZ0AhnRfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scraped_content.split('. ')[0]"
      ],
      "metadata": {
        "id": "AdkGjjB4EX7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resp = prompt_engineered_api(scraped_content.split('. ')[0])\n",
        "\n",
        "resp"
      ],
      "metadata": {
        "id": "OQWijSDioC_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(resp)"
      ],
      "metadata": {
        "id": "OdAYvuqbpaDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create `DatasetDict` Data Structure"
      ],
      "metadata": {
        "id": "gmEAm01lArA0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "# Example data - replace these with your actual data\n",
        "train_data = {'text': [resp]*3}\n",
        "test_data = {'text': [resp]*2}\n",
        "\n",
        "# Create Dataset objects for training and testing\n",
        "train_dataset = Dataset.from_dict(train_data)\n",
        "test_dataset = Dataset.from_dict(test_data)\n",
        "\n",
        "# Combine them into a DatasetDict\n",
        "dataset_dict = DatasetDict({\n",
        "    'train': train_dataset,\n",
        "    'test': test_dataset\n",
        "})\n",
        "\n",
        "# Display the structure of the dataset\n",
        "print(dataset_dict)\n",
        "```"
      ],
      "metadata": {
        "id": "_qv9VmkMuBU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "tD6CuQrFrhWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_content_for_train = []\n",
        "\n",
        "for i in tqdm(range(len(scraped_content.split('. ')))):\n",
        "    resp = prompt_engineered_api(scraped_content.split('. ')[i])\n",
        "    raw_content_for_train.append(resp)"
      ],
      "metadata": {
        "id": "9kAeOgwGpsV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_content_for_train[0]"
      ],
      "metadata": {
        "id": "xD9kHfxZuxMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example data - replace these with your actual data\n",
        "train_data = {'text': raw_content_for_train[0:100]}\n",
        "test_data = {'text': raw_content_for_train[100::]}\n",
        "\n",
        "# Create Dataset objects for training and testing\n",
        "train_dataset = Dataset.from_dict(train_data)\n",
        "test_dataset = Dataset.from_dict(test_data)\n",
        "\n",
        "# Combine them into a DatasetDict\n",
        "dataset_dict = DatasetDict({\n",
        "    'train': train_dataset,\n",
        "    'test': test_dataset\n",
        "})\n",
        "\n",
        "# Display the structure of the dataset\n",
        "print(dataset_dict)"
      ],
      "metadata": {
        "id": "ryMUfedLp3Hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dict[\"train\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "tBDtLLa4r1ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Push to HuggingFace Hub"
      ],
      "metadata": {
        "id": "xTqknyL_Aw5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! huggingface-cli login"
      ],
      "metadata": {
        "id": "w5jm2qfmsFCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi, create_repo"
      ],
      "metadata": {
        "id": "VeK-gKl531a3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 'your_token_here' with your actual Hugging Face Auth token\n",
        "# Replace 'youthless-homeless-shelter-web-scrape-dataset' with your desired repository name\n",
        "auth_token = 'xxx'\n",
        "repo_name = 'jvm_troubleshooting_guide'\n",
        "username = 'CesarChaMal' # replace with your Hugging Face username\n",
        "\n",
        "api = HfApi()\n",
        "create_repo(repo_name, token=auth_token, private=False) # Set private=True if you want it to be a private dataset\n"
      ],
      "metadata": {
        "id": "_nY3yXFi32G3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app_id = f\"{username}/{repo_name}\"\n",
        "print(app_id)"
      ],
      "metadata": {
        "id": "ixYNdItB4Fto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dict.push_to_hub(app_id)"
      ],
      "metadata": {
        "id": "2dVxrZKkscJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Rf2pADU0ZZh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}