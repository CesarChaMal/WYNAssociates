{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NoqVwaMers58"
      },
      "source": [
        "# Custom Agent with PlugIn Retrieval\n",
        "\n",
        "This notebook combines two concepts in order to build a custom agent that can interact with AI Plugins:\n",
        "\n",
        "1. [Custom Agent with Tool Retrieval](https://python.langchain.com/docs/modules/agents/how_to/custom_agent_with_tool_retrieval.html): This introduces the concept of retrieving many tools, which is useful when trying to work with arbitrarily many plugins.\n",
        "\n",
        "2. [Natural Language API Chains](https://python.langchain.com/docs/modules/chains/additional/openapi.html): This creates Natural Language wrappers around OpenAPI endpoints. This is useful because (1) plugins use OpenAPI endpoints under the hood, (2) wrapping them in an NLAChain allows the router agent to call it more easily.\n",
        "\n",
        "The novel idea introduced in this notebook is the idea of using retrieval to select not the tools explicitly, but the set of OpenAPI specs to use. We can then generate tools from those OpenAPI specs. The use case for this is when trying to get agents to use plugins. It may be more efficient to choose plugins first, then the endpoints, rather than the endpoints directly. This is because the plugins may contain more useful information for selection."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UptyqQSbsZUe"
      },
      "source": [
        "I want to give credits to this [Langchain Doc](https://python.langchain.com/docs/use_cases/agents/custom_agent_with_plugin_retrieval.html#set-up-environment)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bF3yMqcqoFXQ"
      },
      "source": [
        "## Set up environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjs17ct2oBln",
        "outputId": "02d7a7fe-33bd-4296-ee3d-dc7cc4da0892"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.224-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.16)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.5.9-py3-none-any.whl (26 kB)\n",
            "Collecting langchainplus-sdk<0.0.21,>=0.0.20 (from langchain)\n",
            "  Downloading langchainplus_sdk-0.0.20-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.9)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.3.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting typing-inspect>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, openapi-schema-pydantic, marshmallow-enum, langchainplus-sdk, openai, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.5.9 langchain-0.0.224 langchainplus-sdk-0.0.20 marshmallow-3.19.0 marshmallow-enum-1.5.1 mypy-extensions-1.0.0 openai-0.27.8 openapi-schema-pydantic-1.2.4 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "pip install langchain openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "b8m-Lv3PoAnL"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import (\n",
        "    Tool,\n",
        "    AgentExecutor,\n",
        "    LLMSingleActionAgent,\n",
        "    AgentOutputParser,\n",
        ")\n",
        "from langchain.prompts import StringPromptTemplate\n",
        "from langchain import OpenAI, SerpAPIWrapper, LLMChain\n",
        "from typing import List, Union\n",
        "from langchain.schema import AgentAction, AgentFinish\n",
        "from langchain.agents.agent_toolkits import NLAToolkit\n",
        "from langchain.tools.plugin import AIPlugin\n",
        "import re"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "C2EQH1xooHXz"
      },
      "source": [
        "## Setup LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pkCvRoNQoRxP"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import openai"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0y5peyznstqk"
      },
      "source": [
        "You might want to consider one of the following ways as well if needed:\n",
        "\n",
        "```\n",
        "openai.api_key = \"<ENTER YOUR OPENAI KEY HERE>\"\n",
        "!export OPENAI_API_KEY=\"<ENTER YOUR OPENAI KEY HERE>\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "jqihTqe6oBNz"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(temperature=0, openai_api_key=\"<ENTER YOUR OPENAI KEY HERE>\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MfWSqG-aoh2n"
      },
      "source": [
        "## Set up plugins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ugaVg0skoI8q"
      },
      "outputs": [],
      "source": [
        "urls = [\n",
        "    \"https://datasette.io/.well-known/ai-plugin.json\",\n",
        "    \"https://api.speak.com/.well-known/ai-plugin.json\",\n",
        "    \"https://www.wolframalpha.com/.well-known/ai-plugin.json\",\n",
        "    \"https://www.zapier.com/.well-known/ai-plugin.json\",\n",
        "    \"https://www.klarna.com/.well-known/ai-plugin.json\",\n",
        "    \"https://www.joinmilo.com/.well-known/ai-plugin.json\",\n",
        "    \"https://slack.com/.well-known/ai-plugin.json\",\n",
        "    \"https://schooldigger.com/.well-known/ai-plugin.json\",\n",
        "]\n",
        "\n",
        "AI_PLUGINS = [AIPlugin.from_url(url) for url in urls]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5CDQmD1-okMm"
      },
      "source": [
        "## Tool Retriever\n",
        "\n",
        "We will use a vectorstore to create embeddings for each tool description. Then, for an incoming query we can create embeddings for that query and do a similarity search for relevant tools.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "qO7BndXtogwA"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.schema import Document"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bNUiZedjqUPp"
      },
      "source": [
        "You might see:\n",
        "\n",
        "```\n",
        "ImportError: Could not import tiktoken python package. This is needed in order to for OpenAIEmbeddings. Please install it with `pip install tiktoken`.\n",
        "```\n",
        "\n",
        "So please install: `pip install tiktoken`\n",
        "\n",
        "Same with:\n",
        "\n",
        "```\n",
        "ImportError: Could not import faiss python package. Please install it with `pip install faiss` or `pip install faiss-cpu` (depending on Python version).\n",
        "```\n",
        "\n",
        "For example, say I'm in a regular Colab version using CPU and I'll be using `pip install faiss-cpu`."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cgkvshCGs7Gf"
      },
      "source": [
        "You can use the following to install the required packages in Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqQQ_iZ3qaJ7",
        "outputId": "02358574-fcfc-4574-a6aa-bbff59e3f570"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Installing collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.4\n"
          ]
        }
      ],
      "source": [
        "pip install tiktoken faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrjxW078ojTe",
        "outputId": "1589096b-f4db-4d23-8d9a-7cf088894bce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain.utilities.openapi:Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
            "WARNING:langchain.utilities.openapi:Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
            "WARNING:langchain.utilities.openapi:Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
            "WARNING:langchain.utilities.openapi:Attempting to load an OpenAPI 3.0.2 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
            "WARNING:langchain.utilities.openapi:Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
            "WARNING:langchain.utilities.openapi:Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
            "WARNING:langchain.utilities.openapi:Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
            "WARNING:langchain.utilities.openapi:Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
            "WARNING:langchain.utilities.openapi:Attempting to load a Swagger 2.0 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n"
          ]
        }
      ],
      "source": [
        "embeddings = OpenAIEmbeddings(openai_api_key=\"<ENTER YOUR OPENAI KEY HERE>\")\n",
        "docs = [\n",
        "    Document(\n",
        "        page_content=plugin.description_for_model,\n",
        "        metadata={\"plugin_name\": plugin.name_for_model},\n",
        "    )\n",
        "    for plugin in AI_PLUGINS\n",
        "]\n",
        "vector_store = FAISS.from_documents(docs, embeddings)\n",
        "toolkits_dict = {\n",
        "    plugin.name_for_model: NLAToolkit.from_llm_and_ai_plugin(llm, plugin)\n",
        "    for plugin in AI_PLUGINS\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "O7nyEC-JomZc"
      },
      "outputs": [],
      "source": [
        "retriever = vector_store.as_retriever()\n",
        "\n",
        "\n",
        "def get_tools(query):\n",
        "    # Get documents, which contain the Plugins to use\n",
        "    docs = retriever.get_relevant_documents(query)\n",
        "    # Get the toolkits, one for each plugin\n",
        "    tool_kits = [toolkits_dict[d.metadata[\"plugin_name\"]] for d in docs]\n",
        "    # Get the tools: a separate NLAChain for each endpoint\n",
        "    tools = []\n",
        "    for tk in tool_kits:\n",
        "        tools.extend(tk.nla_tools)\n",
        "    return tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K00X74uKq7vb",
        "outputId": "f49ee373-3a13-4864-a263-4ef6bc869430"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Milo.askMilo',\n",
              " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.search_all_actions',\n",
              " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.preview_a_zap',\n",
              " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.get_configuration_link',\n",
              " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.list_exposed_actions',\n",
              " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.get_execution_log_endpoint',\n",
              " 'SchoolDigger_API_V2.0.Autocomplete_GetSchools',\n",
              " 'SchoolDigger_API_V2.0.Districts_GetAllDistricts2',\n",
              " 'SchoolDigger_API_V2.0.Districts_GetDistrict2',\n",
              " 'SchoolDigger_API_V2.0.Rankings_GetSchoolRank2',\n",
              " 'SchoolDigger_API_V2.0.Rankings_GetRank_District',\n",
              " 'SchoolDigger_API_V2.0.Schools_GetAllSchools20',\n",
              " 'SchoolDigger_API_V2.0.Schools_GetSchool20',\n",
              " 'Open_AI_Klarna_product_Api.productsUsingGET']"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tools = get_tools(\"What could I do today with my kiddo\")\n",
        "[t.name for t in tools]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hryLAR3GrBLB"
      },
      "source": [
        "## Prompt Template\n",
        "\n",
        "The prompt template is pretty standard, because we're not actually changing that much logic in the actual prompt template, but rather we are just changing how retrieval is done.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "mbZE7pTjq8x1"
      },
      "outputs": [],
      "source": [
        "# Set up the base template\n",
        "template = \"\"\"Answer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\n",
        "\n",
        "{tools}\n",
        "\n",
        "Use the following format:\n",
        "\n",
        "Question: the input question you must answer\n",
        "Thought: you should always think about what to do\n",
        "Action: the action to take, should be one of [{tool_names}]\n",
        "Action Input: the input to the action\n",
        "Observation: the result of the action\n",
        "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "Thought: I now know the final answer\n",
        "Final Answer: the final answer to the original input question\n",
        "\n",
        "Begin! Remember to speak as a pirate when giving your final answer. Use lots of \"Arg\"s\n",
        "\n",
        "Question: {input}\n",
        "{agent_scratchpad}\"\"\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "O1pylsp4rEsm"
      },
      "source": [
        "The custom prompt template now has the concept of a tools_getter, which we call on the input to select the tools to use\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "K3_1h83crDpV"
      },
      "outputs": [],
      "source": [
        "from typing import Callable\n",
        "\n",
        "\n",
        "# Set up a prompt template\n",
        "class CustomPromptTemplate(StringPromptTemplate):\n",
        "    # The template to use\n",
        "    template: str\n",
        "    ############## NEW ######################\n",
        "    # The list of tools available\n",
        "    tools_getter: Callable\n",
        "\n",
        "    def format(self, **kwargs) -> str:\n",
        "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
        "        # Format them in a particular way\n",
        "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
        "        thoughts = \"\"\n",
        "        for action, observation in intermediate_steps:\n",
        "            thoughts += action.log\n",
        "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
        "        # Set the agent_scratchpad variable to that value\n",
        "        kwargs[\"agent_scratchpad\"] = thoughts\n",
        "        ############## NEW ######################\n",
        "        tools = self.tools_getter(kwargs[\"input\"])\n",
        "        # Create a tools variable from the list of tools provided\n",
        "        kwargs[\"tools\"] = \"\\n\".join(\n",
        "            [f\"{tool.name}: {tool.description}\" for tool in tools]\n",
        "        )\n",
        "        # Create a list of tool names for the tools provided\n",
        "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in tools])\n",
        "        return self.template.format(**kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "4xXkeZJXrF7Q"
      },
      "outputs": [],
      "source": [
        "prompt = CustomPromptTemplate(\n",
        "    template=template,\n",
        "    tools_getter=get_tools,\n",
        "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
        "    # This includes the `intermediate_steps` variable because that is needed\n",
        "    input_variables=[\"input\", \"intermediate_steps\"],\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "d7vaMNR9rI-l"
      },
      "source": [
        "## Output Parser\n",
        "\n",
        "The output parser is unchanged from the previous notebook, since we are not changing anything about the output format.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Fd5iz-bHrHYK"
      },
      "outputs": [],
      "source": [
        "class CustomOutputParser(AgentOutputParser):\n",
        "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
        "        # Check if agent should finish\n",
        "        if \"Final Answer:\" in llm_output:\n",
        "            return AgentFinish(\n",
        "                # Return values is generally always a dictionary with a single `output` key\n",
        "                # It is not recommended to try anything else at the moment :)\n",
        "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
        "                log=llm_output,\n",
        "            )\n",
        "        # Parse out the action and action input\n",
        "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
        "        match = re.search(regex, llm_output, re.DOTALL)\n",
        "        if not match:\n",
        "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
        "        action = match.group(1).strip()\n",
        "        action_input = match.group(2)\n",
        "        # Return the action and action input\n",
        "        return AgentAction(\n",
        "            tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "kVlKW74XrK_Z"
      },
      "outputs": [],
      "source": [
        "output_parser = CustomOutputParser()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GUHa1NIDrXLI"
      },
      "source": [
        "## Set up LLM, stop sequence, and the agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "M_qcsg1ZrL7H"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(temperature=0, openai_api_key=\"<ENTER YOUR OPENAI KEY HERE>\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "imFBSBj5rYyJ"
      },
      "outputs": [],
      "source": [
        "# LLM chain consisting of the LLM and a prompt\n",
        "llm_chain = LLMChain(llm=llm, prompt=prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "3WAo2knprfzY"
      },
      "outputs": [],
      "source": [
        "tool_names = [tool.name for tool in tools]\n",
        "agent = LLMSingleActionAgent(\n",
        "    llm_chain=llm_chain,\n",
        "    output_parser=output_parser,\n",
        "    stop=[\"\\nObservation:\"],\n",
        "    allowed_tools=tool_names,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Xyl-njLerhgj"
      },
      "source": [
        "## Use the Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "0hY1F4t-rglE"
      },
      "outputs": [],
      "source": [
        "agent_executor = AgentExecutor.from_agent_and_tools(\n",
        "    agent=agent, tools=tools, verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "hXkSGI4RrihI",
        "outputId": "a97b8c2e-039b-4ae9-88a3-7859467b2c4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to find a way to get product information\n",
            "Action: Open_AI_Klarna_product_Api.productsUsingGET\n",
            "Action Input: shirts\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:275: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Observation:\u001b[33;1m\u001b[1;3mI found 10 shirts from the API response. They are from brands such as Burberry, Calvin Klein, Casablanca, Cubavera, KingSize, and Tommy Bahama. The shirts come in a variety of colors, sizes, and materials. Prices range from $10.98 to $503.00.\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I now know what shirts I can buy\n",
            "Final Answer: Arg, I found 10 shirts from the API response. They be from brands such as Burberry, Calvin Klein, Casablanca, Cubavera, KingSize, and Tommy Bahama. The shirts come in a variety of colors, sizes, and materials. Prices range from $10.98 to $503.00.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Arg, I found 10 shirts from the API response. They be from brands such as Burberry, Calvin Klein, Casablanca, Cubavera, KingSize, and Tommy Bahama. The shirts come in a variety of colors, sizes, and materials. Prices range from $10.98 to $503.00.'"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_executor.run(\"what shirts can i buy?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6kRNum-rjOT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
