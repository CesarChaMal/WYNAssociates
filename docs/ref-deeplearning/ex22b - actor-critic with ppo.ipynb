{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Proximal Policy Optimization (PPO) with TensorFlow\n",
        "\n",
        "Understanding PPO reinforcement learning algorithm and implementing it with TensorFlow 2.x\n",
        "\n",
        "![image](https://miro.medium.com/max/1400/1*XreRjuz6MmATuoRvmprsdA.webp)\n",
        "\n",
        "The source of the notes come from this [blog](https://towardsdatascience.com/proximal-policy-optimization-ppo-with-tensorflow-2-x-89c9430ecc26).\n",
        "\n",
        "In this article, we will try to understand Open-AI’s Proximal Policy Optimization algorithm for reinforcement learning. After some basic theory, we will be implementing PPO with TensorFlow 2.x. Before you read further, I would recommend you take a look at the Actor-Critic method from [here](https://towardsdatascience.com/actor-critic-with-tensorflow-2-x-part-2of-2-b8ceb7e059db), as we will be modifying the code of that article for PPO.\n",
        "\n"
      ],
      "metadata": {
        "id": "DqQ4zNKh7fCR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why PPO?\n",
        "\n",
        "1. *Unstable Policy Update*: In Many Policy Gradient Methods, policy updates are unstable because of larger step size, which leads to bad policy updates and when this new bad policy is used for learning then it leads to even worse policy. And if steps are small then it leads to slower learning.\n",
        "\n",
        "2. *Data Inefficiency*: Many learning methods learn from current experience and discard the experiences after gradient updates. This makes the learning process slow as a neural net takes lots of data to learn.\n",
        "\n",
        "PPO comes handy to overcome the above issues.\n",
        "\n",
        "### Core Idea Behind PPO\n",
        "\n",
        "In earlier Policy gradient methods, the objective function was something like $\\hat{\\mathbb{E}}[\\log \\pi_{\\theta}(a_t/s_t) \\cdot \\hat{A}_t]$. But now instead of the log of current policy, we will be taking the ratio of current policy and old policy.\n",
        "\n",
        "$$\\hat{\\mathbb{E}} \\big[\\frac{\\pi_{\\theta}(a_t | s_t)}{\\pi_{\\theta_{\\text{old}}}(a_t|s_t)} \\hat{A}_t \\big] = \\hat{\\mathbb{E}} \\big[r_t(\\theta) \\hat{A}_t \\big]$$\n",
        "\n",
        "Equation comes from this [paper](https://arxiv.org/abs/1707.06347).\n",
        "\n",
        "We will be also clipping the ratio and will the minimum of the two i.e b/w clipped and unclipped.\n",
        "\n",
        "$$L^{\\text{CLIP}(\\theta)} = \\hat{\\mathbb{E}} \\big[\\min(r_t(\\theta) \\hat{A}_t, \\text{clip}(r_t(\\theta), 1-\\epsilon, 1+\\epsilon) \\hat{A}_t\\big]$$\n",
        "\n",
        "This clipped objective will restrict large policy updates as shown below.\n",
        "\n",
        "![image](https://miro.medium.com/max/1400/1*VN01Obh5VyJ6QuA0qfyq6w.webp)\n",
        "\n",
        "Photo from this [paper](https://arxiv.org/abs/1707.06347)\n"
      ],
      "metadata": {
        "id": "cm-keDbJ7vdq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algorithm Steps\n",
        "\n",
        "1. Play game for n steps and store state, action probability, rewards, done variables.\n",
        "2. Apply the Generalized Advantage Estimation method on the above experience. We will see this in the coding section.\n",
        "3. Train neural networks for some epochs by calculating their respective loss.\n",
        "4. Test this trained model for “m” episodes.\n",
        "5. If the average reward of test episodes is larger than the target reward set by you then stop otherwise repeat from step one."
      ],
      "metadata": {
        "id": "R85BryFj9ONY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code\n",
        "\n",
        "1. After importing the required libraries and initializing our environment, we define our neural networks and are similar to that of the Actor-Critic article.\n",
        "2. The Actor-network takes the current state as input and outputs probability for each action.\n",
        "3. The Critic network outputs the value of a state.\n",
        "\n",
        "```py\n",
        "class critic():\n",
        "    # here is a neural network with dense layers\n",
        "\n",
        "class actor():\n",
        "    # here is another neural network with dense layers\n",
        "```"
      ],
      "metadata": {
        "id": "L5LFkLfq9ZNF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Action Selection\n",
        "\n",
        "1. We define our agent class and initialize optimizer and learning rate.\n",
        "2. We also define a clip_pram variable which will be used in the actor loss function.\n",
        "3. For action selection, we will be using the TensorFlow probabilities library, which takes probabilities as input and convert them into distribution.\n",
        "4. Then, we use the distribution for action selection.\n",
        "\n",
        "```py\n",
        "class agent()\n",
        "    def __init__(self):\n",
        "        # define optimizer\n",
        "        # define actor()\n",
        "        # define critic()\n",
        "    \n",
        "    def act(self, state):\n",
        "        # define what the actor does\n",
        "    \n",
        "    def actor_loss(self, prob, action, td):\n",
        "        # define the formuls\n",
        "        # and compute the loss for actor\n",
        "        # loss is defined according to PPO formula\n",
        "    \n",
        "    def learn():\n",
        "        # use gradient tape to update gradient\n",
        "        # according to PPO loss function\n",
        "```"
      ],
      "metadata": {
        "id": "mk3HBlzr9uDq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Model Knolwedge\n",
        "\n",
        "This function will be used to test our agent’s knowledge and returns the total reward for one episode.\n",
        "\n",
        "```py\n",
        "def test_reward(env):\n",
        "    # there we have a while-loop to update reward\n",
        "```"
      ],
      "metadata": {
        "id": "I4J_7zzL-Bsd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop\n",
        "\n",
        "1. We will loop for “steps” time i.e we will collect experience for “steps” time.\n",
        "2. The next loop is for the number of times agent interacts with environments and we store experiences in different lists.\n",
        "3. After the above loop, we calculate and add the value of the state next to the last state for calculations in the Generalized Advantage Estimation method.\n",
        "4. Then, we process all the lists in the Generalized Advantage Estimation method to get returns, advantage.\n",
        "5. Next, we train our networks for 10 epochs.\n",
        "6. After training, we will test our agent on the test environment for five episodes.\n",
        "7. If the average reward of test episodes is larger than the target reward set by you then stop otherwise repeat from step one.\n",
        "\n",
        "```py\n",
        "# define params\n",
        "for s in range(steps):\n",
        "    for s in range(steps):\n",
        "        # define params for inner loop\n",
        "        # compute actions, probabilities, values\n",
        "        reward.append()\n",
        "        actions.append()\n",
        "        probs.append()\n",
        "        values.append()\n",
        "    for epochs in range(10):\n",
        "        # run \n",
        "        agent().learn()\n",
        "        # which use gradient tape to update gradient\n",
        "    \n",
        "    # clean up\n",
        "    # and print results\n",
        "    # and save\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "tV2hpfEf-Lej"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code Starts from Here"
      ],
      "metadata": {
        "id": "L5voX6Hj_ZT-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Library"
      ],
      "metadata": {
        "id": "ShYHZIh7_dmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf \n",
        "import gym\n",
        "import tensorflow_probability as tfp\n",
        "import tensorflow.keras.losses as kls"
      ],
      "metadata": {
        "id": "xYIvgSYn5hUc"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installation\n",
        "\n",
        "Please install the following."
      ],
      "metadata": {
        "id": "n6F2yJXI_f3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install box2d-py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2UxFdDS6YdT",
        "outputId": "0e183db7-ebc8-47db-db4a-b02cf5ace33f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting box2d-py\n",
            "  Downloading box2d-py-2.3.8.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.5/374.5 KB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.8-cp38-cp38-linux_x86_64.whl size=2835001 sha256=1aac00046f2e9a376195a72d2aa31ee39ec050a0df36c3e51c1d5107bf61c9d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/4f/d6/44eb0a9e6fea384e58f19cb0c4125e46a23af2b33fe3a7e81c\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gym[box2d]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sV1JyU3u6VmG",
        "outputId": "9da39afe-d59a-4bf0-e396-dd61b910cdbd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[box2d] in /usr/local/lib/python3.8/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from gym[box2d]) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from gym[box2d]) (6.0.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym[box2d]) (0.0.8)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym[box2d]) (2.2.0)\n",
            "Requirement already satisfied: swig==4.* in /usr/local/lib/python3.8/dist-packages (from gym[box2d]) (4.1.1)\n",
            "Collecting pygame==2.1.0\n",
            "  Using cached pygame-2.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Collecting box2d-py==2.3.5\n",
            "  Using cached box2d-py-2.3.5.tar.gz (374 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.0->gym[box2d]) (3.11.0)\n",
            "Building wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp38-cp38-linux_x86_64.whl size=2834814 sha256=130ff3883c95bb2e24e10d15454a08019dc496fcd2aa4e4f5e069e4a2325d292\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/95/16/1dc99ff9a3f316ff245fdb5c9086cd13c35dad630809909075\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: box2d-py, pygame\n",
            "  Attempting uninstall: box2d-py\n",
            "    Found existing installation: box2d-py 2.3.8\n",
            "    Uninstalling box2d-py-2.3.8:\n",
            "      Successfully uninstalled box2d-py-2.3.8\n",
            "Successfully installed box2d-py-2.3.5 pygame-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initiate Environment\n",
        "\n",
        "We use the `Cart Pole` environment from [gym](https://www.gymlibrary.dev/environments/classic_control/cart_pole/)."
      ],
      "metadata": {
        "id": "CaGSFskn_jh0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQly4cTp5VjL",
        "outputId": "c6dc6c1e-7be2-4c24-9321-5771fe515187"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ],
      "source": [
        "env = gym.make(\"CartPole-v0\")\n",
        "low = env.observation_space.low\n",
        "high = env.observation_space.high"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Class Object: `critic`"
      ],
      "metadata": {
        "id": "ony4paV9_m2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class critic(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.d1 = tf.keras.layers.Dense(128,activation='relu')\n",
        "        self.v = tf.keras.layers.Dense(1, activation = None)\n",
        "\n",
        "    def call(self, input_data):\n",
        "        x = self.d1(input_data)\n",
        "        v = self.v(x)\n",
        "        return v\n",
        "\n",
        "\n",
        "class actor(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.d1 = tf.keras.layers.Dense(128,activation='relu')\n",
        "        self.a = tf.keras.layers.Dense(2,activation='softmax')\n",
        "\n",
        "    def call(self, input_data):\n",
        "        x = self.d1(input_data)\n",
        "        a = self.a(x)\n",
        "        return a"
      ],
      "metadata": {
        "id": "2Ca4f7_f5ik7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Class Object: `agent`"
      ],
      "metadata": {
        "id": "h16OUE1o_uan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class agent():\n",
        "    def __init__(self, gamma = 0.99):\n",
        "        self.gamma = gamma\n",
        "        # self.a_opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "        # self.c_opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "        self.a_opt = tf.keras.optimizers.Adam(learning_rate=7e-3)\n",
        "        self.c_opt = tf.keras.optimizers.Adam(learning_rate=7e-3)\n",
        "        self.actor = actor()\n",
        "        self.critic = critic()\n",
        "        self.clip_pram = 0.2\n",
        "\n",
        "\n",
        "    def act(self,state):\n",
        "        prob = self.actor(np.array([state]))\n",
        "        prob = prob.numpy()\n",
        "        dist = tfp.distributions.Categorical(probs=prob, dtype=tf.float32)\n",
        "        action = dist.sample()\n",
        "        return int(action.numpy()[0])\n",
        "\n",
        "\n",
        "    def actor_loss(self, probs, actions, adv, old_probs, closs):\n",
        "\n",
        "        probability = probs      \n",
        "        entropy = tf.reduce_mean(tf.math.negative(tf.math.multiply(probability,tf.math.log(probability))))\n",
        "        #print(probability)\n",
        "        #print(entropy)\n",
        "        sur1 = []\n",
        "        sur2 = []\n",
        "\n",
        "        for pb, t, op,a  in zip(probability, adv, old_probs, actions):\n",
        "            t =  tf.constant(t)\n",
        "            #op =  tf.constant(op)\n",
        "            #print(f\"t{t}\")\n",
        "            #ratio = tf.math.exp(tf.math.log(pb + 1e-10) - tf.math.log(op + 1e-10))\n",
        "            ratio = tf.math.divide(pb[a],op[a])\n",
        "            #print(f\"ratio{ratio}\")\n",
        "            s1 = tf.math.multiply(ratio,t)\n",
        "            #print(f\"s1{s1}\")\n",
        "            s2 =  tf.math.multiply(tf.clip_by_value(ratio, 1.0 - self.clip_pram, 1.0 + self.clip_pram),t)\n",
        "            #print(f\"s2{s2}\")\n",
        "            sur1.append(s1)\n",
        "            sur2.append(s2)\n",
        "\n",
        "        sr1 = tf.stack(sur1)\n",
        "        sr2 = tf.stack(sur2)\n",
        "        \n",
        "        #closs = tf.reduce_mean(tf.math.square(td))\n",
        "        loss = tf.math.negative(tf.reduce_mean(tf.math.minimum(sr1, sr2)) - closs + 0.001 * entropy)\n",
        "        #print(loss)\n",
        "        return loss\n",
        "\n",
        "    def learn(self, states, actions,  adv , old_probs, discnt_rewards):\n",
        "        discnt_rewards = tf.reshape(discnt_rewards, (len(discnt_rewards),))\n",
        "        adv = tf.reshape(adv, (len(adv),))\n",
        "\n",
        "        old_p = old_probs\n",
        "        old_p = tf.reshape(old_p, (len(old_p),2))\n",
        "\n",
        "        with tf.GradientTape() as tape1, tf.GradientTape() as tape2:\n",
        "            p = self.actor(states, training=True)\n",
        "            v =  self.critic(states,training=True)\n",
        "            v = tf.reshape(v, (len(v),))\n",
        "            td = tf.math.subtract(discnt_rewards, v)\n",
        "            c_loss = 0.5 * kls.mean_squared_error(discnt_rewards, v)\n",
        "            a_loss = self.actor_loss(p, actions, adv, old_probs, c_loss)\n",
        "\n",
        "        grads1 = tape1.gradient(a_loss, self.actor.trainable_variables)\n",
        "        grads2 = tape2.gradient(c_loss, self.critic.trainable_variables)\n",
        "        self.a_opt.apply_gradients(zip(grads1, self.actor.trainable_variables))\n",
        "        self.c_opt.apply_gradients(zip(grads2, self.critic.trainable_variables))\n",
        "\n",
        "        return a_loss, c_loss"
      ],
      "metadata": {
        "id": "86hwMCju5nSJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_reward(env):\n",
        "    total_reward = 0\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    while not done:\n",
        "        action = np.argmax(agentoo7.actor(np.array([state])).numpy())\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "\n",
        "    return total_reward"
      ],
      "metadata": {
        "id": "FdDH34HUA45f"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess1(states, actions, rewards, done, values, gamma):\n",
        "    g = 0\n",
        "    lmbda = 0.95\n",
        "    returns = []\n",
        "    for i in reversed(range(len(rewards))):\n",
        "        delta = rewards[i] + gamma * values[i + 1] * done[i] - values[i]\n",
        "        g = delta + gamma * lmbda * dones[i] * g\n",
        "        returns.append(g + values[i])\n",
        "\n",
        "    returns.reverse()\n",
        "    adv = np.array(returns, dtype=np.float32) - values[:-1]\n",
        "    adv = (adv - np.mean(adv)) / (np.std(adv) + 1e-10)\n",
        "    states = np.array(states, dtype=np.float32)\n",
        "    actions = np.array(actions, dtype=np.int32)\n",
        "    returns = np.array(returns, dtype=np.float32)\n",
        "\n",
        "    return states, actions, returns, adv    "
      ],
      "metadata": {
        "id": "70Hl3RsXA8gd"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define and Run Training"
      ],
      "metadata": {
        "id": "mnwj-IYm_wHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(2023)\n",
        "agentoo7 = agent()\n",
        "steps = 1000000\n",
        "ep_reward = []\n",
        "total_avgr = []\n",
        "target = False \n",
        "best_reward = 0\n",
        "avg_rewards_list = []\n",
        "for s in range(steps):\n",
        "    print(f'START: Running step = {s} now =====================================')\n",
        "    if target == True:\n",
        "        break\n",
        "\n",
        "    done = False\n",
        "    state = env.reset()\n",
        "    all_aloss = []\n",
        "    all_closs = []\n",
        "    rewards = []\n",
        "    states = []\n",
        "    actions = []\n",
        "    probs = []\n",
        "    dones = []\n",
        "    values = []\n",
        "    print(\"new episod\")\n",
        "\n",
        "    for e in range(128):\n",
        "        action = agentoo7.act(state)\n",
        "        value = agentoo7.critic(np.array([state])).numpy()\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        dones.append(1-done)\n",
        "        rewards.append(reward)\n",
        "        states.append(state)\n",
        "        #actions.append(tf.one_hot(action, 2, dtype=tf.int32).numpy().tolist())\n",
        "        actions.append(action)\n",
        "        prob = agentoo7.actor(np.array([state]))\n",
        "        probs.append(prob[0])\n",
        "        values.append(value[0][0])\n",
        "        state = next_state\n",
        "        if done:\n",
        "            env.reset()\n",
        "\n",
        "    value = agentoo7.critic(np.array([state])).numpy()\n",
        "    values.append(value[0][0])\n",
        "    np.reshape(probs, (len(probs),2))\n",
        "    probs = np.stack(probs, axis=0)\n",
        "\n",
        "    states, actions,returns, adv  = preprocess1(states, actions, rewards, dones, values, 1)\n",
        "\n",
        "    for epocs in range(10):\n",
        "        al,cl = agentoo7.learn(states, actions, adv, probs, returns)\n",
        "        # print(f\"al{al}\") \n",
        "        # print(f\"cl{cl}\")\n",
        "\n",
        "    avg_reward = np.mean([test_reward(env) for _ in range(5)])\n",
        "    print(f\"total test reward is {avg_reward}\")\n",
        "    avg_rewards_list.append(avg_reward)\n",
        "    if avg_reward > best_reward:\n",
        "        print('best reward=' + str(avg_reward))\n",
        "        agentoo7.actor.save('model_actor_{}_{}'.format(s, avg_reward), save_format=\"tf\")\n",
        "        agentoo7.critic.save('model_critic_{}_{}'.format(s, avg_reward), save_format=\"tf\")\n",
        "        best_reward = avg_reward\n",
        "    if best_reward == 200:\n",
        "        target = True\n",
        "\n",
        "    print(f'===================================== step {s} finished!')\n",
        "    env.reset()\n",
        "\n",
        "env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybfQbu-s56sR",
        "outputId": "8c0880d4-0168-42a8-a7ce-22eee2327fd3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "START: Running step = 0 now =====================================\n",
            "new episod\n",
            "total test reward is 14.6\n",
            "best reward=14.6\n",
            "===================================== step 0 finished!\n",
            "START: Running step = 1 now =====================================\n",
            "new episod\n",
            "total test reward is 86.6\n",
            "best reward=86.6\n",
            "===================================== step 1 finished!\n",
            "START: Running step = 2 now =====================================\n",
            "new episod\n",
            "total test reward is 26.6\n",
            "===================================== step 2 finished!\n",
            "START: Running step = 3 now =====================================\n",
            "new episod\n",
            "total test reward is 52.6\n",
            "===================================== step 3 finished!\n",
            "START: Running step = 4 now =====================================\n",
            "new episod\n",
            "total test reward is 49.6\n",
            "===================================== step 4 finished!\n",
            "START: Running step = 5 now =====================================\n",
            "new episod\n",
            "total test reward is 159.6\n",
            "best reward=159.6\n",
            "===================================== step 5 finished!\n",
            "START: Running step = 6 now =====================================\n",
            "new episod\n",
            "total test reward is 117.8\n",
            "===================================== step 6 finished!\n",
            "START: Running step = 7 now =====================================\n",
            "new episod\n",
            "total test reward is 57.0\n",
            "===================================== step 7 finished!\n",
            "START: Running step = 8 now =====================================\n",
            "new episod\n",
            "total test reward is 76.2\n",
            "===================================== step 8 finished!\n",
            "START: Running step = 9 now =====================================\n",
            "new episod\n",
            "total test reward is 116.8\n",
            "===================================== step 9 finished!\n",
            "START: Running step = 10 now =====================================\n",
            "new episod\n",
            "total test reward is 182.4\n",
            "best reward=182.4\n",
            "===================================== step 10 finished!\n",
            "START: Running step = 11 now =====================================\n",
            "new episod\n",
            "total test reward is 131.8\n",
            "===================================== step 11 finished!\n",
            "START: Running step = 12 now =====================================\n",
            "new episod\n",
            "total test reward is 175.4\n",
            "===================================== step 12 finished!\n",
            "START: Running step = 13 now =====================================\n",
            "new episod\n",
            "total test reward is 182.4\n",
            "===================================== step 13 finished!\n",
            "START: Running step = 14 now =====================================\n",
            "new episod\n",
            "total test reward is 106.8\n",
            "===================================== step 14 finished!\n",
            "START: Running step = 15 now =====================================\n",
            "new episod\n",
            "total test reward is 78.4\n",
            "===================================== step 15 finished!\n",
            "START: Running step = 16 now =====================================\n",
            "new episod\n",
            "total test reward is 100.6\n",
            "===================================== step 16 finished!\n",
            "START: Running step = 17 now =====================================\n",
            "new episod\n",
            "total test reward is 97.2\n",
            "===================================== step 17 finished!\n",
            "START: Running step = 18 now =====================================\n",
            "new episod\n",
            "total test reward is 76.2\n",
            "===================================== step 18 finished!\n",
            "START: Running step = 19 now =====================================\n",
            "new episod\n",
            "total test reward is 92.8\n",
            "===================================== step 19 finished!\n",
            "START: Running step = 20 now =====================================\n",
            "new episod\n",
            "total test reward is 101.6\n",
            "===================================== step 20 finished!\n",
            "START: Running step = 21 now =====================================\n",
            "new episod\n",
            "total test reward is 103.8\n",
            "===================================== step 21 finished!\n",
            "START: Running step = 22 now =====================================\n",
            "new episod\n",
            "total test reward is 114.0\n",
            "===================================== step 22 finished!\n",
            "START: Running step = 23 now =====================================\n",
            "new episod\n",
            "total test reward is 172.8\n",
            "===================================== step 23 finished!\n",
            "START: Running step = 24 now =====================================\n",
            "new episod\n",
            "total test reward is 189.8\n",
            "best reward=189.8\n",
            "===================================== step 24 finished!\n",
            "START: Running step = 25 now =====================================\n",
            "new episod\n",
            "total test reward is 194.8\n",
            "best reward=194.8\n",
            "===================================== step 25 finished!\n",
            "START: Running step = 26 now =====================================\n",
            "new episod\n",
            "total test reward is 181.0\n",
            "===================================== step 26 finished!\n",
            "START: Running step = 27 now =====================================\n",
            "new episod\n",
            "total test reward is 179.0\n",
            "===================================== step 27 finished!\n",
            "START: Running step = 28 now =====================================\n",
            "new episod\n",
            "total test reward is 174.4\n",
            "===================================== step 28 finished!\n",
            "START: Running step = 29 now =====================================\n",
            "new episod\n",
            "total test reward is 153.2\n",
            "===================================== step 29 finished!\n",
            "START: Running step = 30 now =====================================\n",
            "new episod\n",
            "total test reward is 199.6\n",
            "best reward=199.6\n",
            "===================================== step 30 finished!\n",
            "START: Running step = 31 now =====================================\n",
            "new episod\n",
            "total test reward is 187.2\n",
            "===================================== step 31 finished!\n",
            "START: Running step = 32 now =====================================\n",
            "new episod\n",
            "total test reward is 192.4\n",
            "===================================== step 32 finished!\n",
            "START: Running step = 33 now =====================================\n",
            "new episod\n",
            "total test reward is 125.4\n",
            "===================================== step 33 finished!\n",
            "START: Running step = 34 now =====================================\n",
            "new episod\n",
            "total test reward is 148.8\n",
            "===================================== step 34 finished!\n",
            "START: Running step = 35 now =====================================\n",
            "new episod\n",
            "total test reward is 179.4\n",
            "===================================== step 35 finished!\n",
            "START: Running step = 36 now =====================================\n",
            "new episod\n",
            "total test reward is 154.4\n",
            "===================================== step 36 finished!\n",
            "START: Running step = 37 now =====================================\n",
            "new episod\n",
            "total test reward is 153.6\n",
            "===================================== step 37 finished!\n",
            "START: Running step = 38 now =====================================\n",
            "new episod\n",
            "total test reward is 168.0\n",
            "===================================== step 38 finished!\n",
            "START: Running step = 39 now =====================================\n",
            "new episod\n",
            "total test reward is 193.4\n",
            "===================================== step 39 finished!\n",
            "START: Running step = 40 now =====================================\n",
            "new episod\n",
            "total test reward is 81.2\n",
            "===================================== step 40 finished!\n",
            "START: Running step = 41 now =====================================\n",
            "new episod\n",
            "total test reward is 172.0\n",
            "===================================== step 41 finished!\n",
            "START: Running step = 42 now =====================================\n",
            "new episod\n",
            "total test reward is 166.4\n",
            "===================================== step 42 finished!\n",
            "START: Running step = 43 now =====================================\n",
            "new episod\n",
            "total test reward is 87.6\n",
            "===================================== step 43 finished!\n",
            "START: Running step = 44 now =====================================\n",
            "new episod\n",
            "total test reward is 95.0\n",
            "===================================== step 44 finished!\n",
            "START: Running step = 45 now =====================================\n",
            "new episod\n",
            "total test reward is 149.8\n",
            "===================================== step 45 finished!\n",
            "START: Running step = 46 now =====================================\n",
            "new episod\n",
            "total test reward is 192.4\n",
            "===================================== step 46 finished!\n",
            "START: Running step = 47 now =====================================\n",
            "new episod\n",
            "total test reward is 170.4\n",
            "===================================== step 47 finished!\n",
            "START: Running step = 48 now =====================================\n",
            "new episod\n",
            "total test reward is 200.0\n",
            "best reward=200.0\n",
            "===================================== step 48 finished!\n",
            "START: Running step = 49 now =====================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "RtAsoiNg7XnF"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ep = [i  for i in range(len(avg_rewards_list))]\n",
        "plt.plot( range(len(avg_rewards_list)),avg_rewards_list,'b')\n",
        "plt.title(\"Avg Test Award Vs Test Episodes\")\n",
        "plt.xlabel(\"Test Episodes\")\n",
        "plt.ylabel(\"Average Test Reward\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "LyXfrsBhDWT2",
        "outputId": "3a9d8751-860b-4852-e60d-0b613d796c6c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NvacW5lmDXpR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}