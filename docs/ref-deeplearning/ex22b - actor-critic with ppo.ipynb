{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNHO4RjARYS2GjmJTiFXOWX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Proximal Policy Optimization (PPO) with TensorFlow\n","\n","Understanding PPO reinforcement learning algorithm and implementing it with TensorFlow 2.x\n","\n","![image](https://miro.medium.com/max/1400/1*XreRjuz6MmATuoRvmprsdA.webp)\n","\n","The source of the notes come from this [blog](https://towardsdatascience.com/proximal-policy-optimization-ppo-with-tensorflow-2-x-89c9430ecc26).\n","\n","In this article, we will try to understand Open-AI’s Proximal Policy Optimization algorithm for reinforcement learning. After some basic theory, we will be implementing PPO with TensorFlow 2.x. Before you read further, I would recommend you take a look at the Actor-Critic method from [here](https://towardsdatascience.com/actor-critic-with-tensorflow-2-x-part-2of-2-b8ceb7e059db), as we will be modifying the code of that article for PPO.\n","\n"],"metadata":{"id":"DqQ4zNKh7fCR"}},{"cell_type":"markdown","source":["## Why PPO?\n","\n","1. *Unstable Policy Update*: In Many Policy Gradient Methods, policy updates are unstable because of larger step size, which leads to bad policy updates and when this new bad policy is used for learning then it leads to even worse policy. And if steps are small then it leads to slower learning.\n","\n","2. *Data Inefficiency*: Many learning methods learn from current experience and discard the experiences after gradient updates. This makes the learning process slow as a neural net takes lots of data to learn.\n","\n","PPO comes handy to overcome the above issues.\n","\n","### Core Idea Behind PPO\n","\n","In earlier Policy gradient methods, the objective function was something like $\\hat{\\mathbb{E}}[\\log \\pi_{\\theta}(a_t/s_t) \\cdot \\hat{A}_t]$. But now instead of the log of current policy, we will be taking the ratio of current policy and old policy.\n","\n","$$\\hat{\\mathbb{E}} \\big[\\frac{\\pi_{\\theta}(a_t | s_t)}{\\pi_{\\theta_{\\text{old}}}(a_t|s_t)} \\hat{A}_t \\big] = \\hat{\\mathbb{E}} \\big[r_t(\\theta) \\hat{A}_t \\big]$$\n","\n","Equation comes from this [paper](https://arxiv.org/abs/1707.06347).\n","\n","We will be also clipping the ratio and will the minimum of the two i.e b/w clipped and unclipped.\n","\n","$$L^{\\text{CLIP}(\\theta)} = \\hat{\\mathbb{E}} \\big[\\min(r_t(\\theta) \\hat{A}_t, \\text{clip}(r_t(\\theta), 1-\\epsilon, 1+\\epsilon) \\hat{A}_t\\big]$$\n","\n","This clipped objective will restrict large policy updates as shown below.\n","\n","![image](https://miro.medium.com/max/1400/1*VN01Obh5VyJ6QuA0qfyq6w.webp)\n","\n","Photo from this [paper](https://arxiv.org/abs/1707.06347)\n"],"metadata":{"id":"cm-keDbJ7vdq"}},{"cell_type":"markdown","source":["## Algorithm Steps\n","\n","1. Play game for n steps and store state, action probability, rewards, done variables.\n","2. Apply the Generalized Advantage Estimation method on the above experience. We will see this in the coding section.\n","3. Train neural networks for some epochs by calculating their respective loss.\n","4. Test this trained model for “m” episodes.\n","5. If the average reward of test episodes is larger than the target reward set by you then stop otherwise repeat from step one."],"metadata":{"id":"R85BryFj9ONY"}},{"cell_type":"markdown","source":["## Code\n","\n","1. After importing the required libraries and initializing our environment, we define our neural networks and are similar to that of the Actor-Critic article.\n","2. The Actor-network takes the current state as input and outputs probability for each action.\n","3. The Critic network outputs the value of a state.\n","\n","```py\n","class critic():\n","    # here is a neural network with dense layers\n","\n","class actor():\n","    # here is another neural network with dense layers\n","```"],"metadata":{"id":"L5LFkLfq9ZNF"}},{"cell_type":"markdown","source":["## Action Selection\n","\n","1. We define our agent class and initialize optimizer and learning rate.\n","2. We also define a clip_pram variable which will be used in the actor loss function.\n","3. For action selection, we will be using the TensorFlow probabilities library, which takes probabilities as input and convert them into distribution.\n","4. Then, we use the distribution for action selection.\n","\n","```py\n","class agent()\n","    def __init__(self):\n","        # define optimizer\n","        # define actor()\n","        # define critic()\n","    \n","    def act(self, state):\n","        # define what the actor does\n","    \n","    def actor_loss(self, prob, action, td):\n","        # define the formuls\n","        # and compute the loss for actor\n","        # loss is defined according to PPO formula\n","    \n","    def learn():\n","        # use gradient tape to update gradient\n","        # according to PPO loss function\n","```"],"metadata":{"id":"mk3HBlzr9uDq"}},{"cell_type":"markdown","source":["## Test Model Knolwedge\n","\n","This function will be used to test our agent’s knowledge and returns the total reward for one episode.\n","\n","```py\n","def test_reward(env):\n","    # there we have a while-loop to update reward\n","```"],"metadata":{"id":"I4J_7zzL-Bsd"}},{"cell_type":"markdown","source":["## Training Loop\n","\n","1. We will loop for “steps” time i.e we will collect experience for “steps” time.\n","2. The next loop is for the number of times agent interacts with environments and we store experiences in different lists.\n","3. After the above loop, we calculate and add the value of the state next to the last state for calculations in the Generalized Advantage Estimation method.\n","4. Then, we process all the lists in the Generalized Advantage Estimation method to get returns, advantage.\n","5. Next, we train our networks for 10 epochs.\n","6. After training, we will test our agent on the test environment for five episodes.\n","7. If the average reward of test episodes is larger than the target reward set by you then stop otherwise repeat from step one.\n","\n","```py\n","# define params\n","for s in range(steps):\n","    for s in range(steps):\n","        # define params for inner loop\n","        # compute actions, probabilities, values\n","        reward.append()\n","        actions.append()\n","        probs.append()\n","        values.append()\n","    for epochs in range(10):\n","        # run \n","        agent().learn()\n","        # which use gradient tape to update gradient\n","    \n","    # clean up\n","    # and print results\n","    # and save\n","\n","```"],"metadata":{"id":"tV2hpfEf-Lej"}},{"cell_type":"markdown","source":["## Code Starts from Here"],"metadata":{"id":"L5voX6Hj_ZT-"}},{"cell_type":"markdown","source":["### Library"],"metadata":{"id":"ShYHZIh7_dmk"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf \n","import gym\n","import tensorflow_probability as tfp\n","import tensorflow.keras.losses as kls"],"metadata":{"id":"xYIvgSYn5hUc","executionInfo":{"status":"ok","timestamp":1674936968530,"user_tz":300,"elapsed":120,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["### Installation\n","\n","Please install the following."],"metadata":{"id":"n6F2yJXI_f3i"}},{"cell_type":"code","source":["pip install box2d-py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y2UxFdDS6YdT","executionInfo":{"status":"ok","timestamp":1674935218336,"user_tz":300,"elapsed":65594,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"0e183db7-ebc8-47db-db4a-b02cf5ace33f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting box2d-py\n","  Downloading box2d-py-2.3.8.tar.gz (374 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.5/374.5 KB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: box2d-py\n","  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for box2d-py: filename=box2d_py-2.3.8-cp38-cp38-linux_x86_64.whl size=2835001 sha256=1aac00046f2e9a376195a72d2aa31ee39ec050a0df36c3e51c1d5107bf61c9d0\n","  Stored in directory: /root/.cache/pip/wheels/cc/4f/d6/44eb0a9e6fea384e58f19cb0c4125e46a23af2b33fe3a7e81c\n","Successfully built box2d-py\n","Installing collected packages: box2d-py\n","Successfully installed box2d-py-2.3.8\n"]}]},{"cell_type":"code","source":["pip install gym[box2d]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sV1JyU3u6VmG","executionInfo":{"status":"ok","timestamp":1674935287118,"user_tz":300,"elapsed":68786,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"9da39afe-d59a-4bf0-e396-dd61b910cdbd"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gym[box2d] in /usr/local/lib/python3.8/dist-packages (0.25.2)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from gym[box2d]) (1.21.6)\n","Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from gym[box2d]) (6.0.0)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym[box2d]) (0.0.8)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym[box2d]) (2.2.0)\n","Requirement already satisfied: swig==4.* in /usr/local/lib/python3.8/dist-packages (from gym[box2d]) (4.1.1)\n","Collecting pygame==2.1.0\n","  Using cached pygame-2.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","Collecting box2d-py==2.3.5\n","  Using cached box2d-py-2.3.5.tar.gz (374 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.0->gym[box2d]) (3.11.0)\n","Building wheels for collected packages: box2d-py\n","  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp38-cp38-linux_x86_64.whl size=2834814 sha256=130ff3883c95bb2e24e10d15454a08019dc496fcd2aa4e4f5e069e4a2325d292\n","  Stored in directory: /root/.cache/pip/wheels/8b/95/16/1dc99ff9a3f316ff245fdb5c9086cd13c35dad630809909075\n","Successfully built box2d-py\n","Installing collected packages: box2d-py, pygame\n","  Attempting uninstall: box2d-py\n","    Found existing installation: box2d-py 2.3.8\n","    Uninstalling box2d-py-2.3.8:\n","      Successfully uninstalled box2d-py-2.3.8\n","Successfully installed box2d-py-2.3.5 pygame-2.1.0\n"]}]},{"cell_type":"markdown","source":["### Initiate Environment"],"metadata":{"id":"CaGSFskn_jh0"}},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BQly4cTp5VjL","executionInfo":{"status":"ok","timestamp":1674936979591,"user_tz":300,"elapsed":155,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"c6dc6c1e-7be2-4c24-9321-5771fe515187"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n","  logger.warn(\n"]}],"source":["env = gym.make(\"CartPole-v0\")\n","low = env.observation_space.low\n","high = env.observation_space.high"]},{"cell_type":"markdown","source":["### Define Class Object: `critic`"],"metadata":{"id":"ony4paV9_m2T"}},{"cell_type":"code","source":["class critic(tf.keras.Model):\n","    def __init__(self):\n","        super().__init__()\n","        self.d1 = tf.keras.layers.Dense(128,activation='relu')\n","        self.v = tf.keras.layers.Dense(1, activation = None)\n","\n","    def call(self, input_data):\n","        x = self.d1(input_data)\n","        v = self.v(x)\n","        return v\n","\n","\n","class actor(tf.keras.Model):\n","    def __init__(self):\n","        super().__init__()\n","        self.d1 = tf.keras.layers.Dense(128,activation='relu')\n","        self.a = tf.keras.layers.Dense(2,activation='softmax')\n","\n","    def call(self, input_data):\n","        x = self.d1(input_data)\n","        a = self.a(x)\n","        return a"],"metadata":{"id":"2Ca4f7_f5ik7","executionInfo":{"status":"ok","timestamp":1674936982008,"user_tz":300,"elapsed":115,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["### Define Class Object: `agent`"],"metadata":{"id":"h16OUE1o_uan"}},{"cell_type":"code","source":["class agent():\n","    def __init__(self, gamma = 0.99):\n","        self.gamma = gamma\n","        # self.a_opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n","        # self.c_opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n","        self.a_opt = tf.keras.optimizers.Adam(learning_rate=7e-3)\n","        self.c_opt = tf.keras.optimizers.Adam(learning_rate=7e-3)\n","        self.actor = actor()\n","        self.critic = critic()\n","        self.clip_pram = 0.2\n","\n","\n","    def act(self,state):\n","        prob = self.actor(np.array([state]))\n","        prob = prob.numpy()\n","        dist = tfp.distributions.Categorical(probs=prob, dtype=tf.float32)\n","        action = dist.sample()\n","        return int(action.numpy()[0])\n","\n","\n","    def actor_loss(self, probs, actions, adv, old_probs, closs):\n","\n","        probability = probs      \n","        entropy = tf.reduce_mean(tf.math.negative(tf.math.multiply(probability,tf.math.log(probability))))\n","        #print(probability)\n","        #print(entropy)\n","        sur1 = []\n","        sur2 = []\n","\n","        for pb, t, op,a  in zip(probability, adv, old_probs, actions):\n","            t =  tf.constant(t)\n","            #op =  tf.constant(op)\n","            #print(f\"t{t}\")\n","            #ratio = tf.math.exp(tf.math.log(pb + 1e-10) - tf.math.log(op + 1e-10))\n","            ratio = tf.math.divide(pb[a],op[a])\n","            #print(f\"ratio{ratio}\")\n","            s1 = tf.math.multiply(ratio,t)\n","            #print(f\"s1{s1}\")\n","            s2 =  tf.math.multiply(tf.clip_by_value(ratio, 1.0 - self.clip_pram, 1.0 + self.clip_pram),t)\n","            #print(f\"s2{s2}\")\n","            sur1.append(s1)\n","            sur2.append(s2)\n","\n","        sr1 = tf.stack(sur1)\n","        sr2 = tf.stack(sur2)\n","        \n","        #closs = tf.reduce_mean(tf.math.square(td))\n","        loss = tf.math.negative(tf.reduce_mean(tf.math.minimum(sr1, sr2)) - closs + 0.001 * entropy)\n","        #print(loss)\n","        return loss\n","\n","    def learn(self, states, actions,  adv , old_probs, discnt_rewards):\n","        discnt_rewards = tf.reshape(discnt_rewards, (len(discnt_rewards),))\n","        adv = tf.reshape(adv, (len(adv),))\n","\n","        old_p = old_probs\n","        old_p = tf.reshape(old_p, (len(old_p),2))\n","\n","        with tf.GradientTape() as tape1, tf.GradientTape() as tape2:\n","            p = self.actor(states, training=True)\n","            v =  self.critic(states,training=True)\n","            v = tf.reshape(v, (len(v),))\n","            td = tf.math.subtract(discnt_rewards, v)\n","            c_loss = 0.5 * kls.mean_squared_error(discnt_rewards, v)\n","            a_loss = self.actor_loss(p, actions, adv, old_probs, c_loss)\n","\n","        grads1 = tape1.gradient(a_loss, self.actor.trainable_variables)\n","        grads2 = tape2.gradient(c_loss, self.critic.trainable_variables)\n","        self.a_opt.apply_gradients(zip(grads1, self.actor.trainable_variables))\n","        self.c_opt.apply_gradients(zip(grads2, self.critic.trainable_variables))\n","\n","        return a_loss, c_loss"],"metadata":{"id":"86hwMCju5nSJ","executionInfo":{"status":"ok","timestamp":1674936982717,"user_tz":300,"elapsed":145,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["def test_reward(env):\n","    total_reward = 0\n","    state = env.reset()\n","    done = False\n","    while not done:\n","        action = np.argmax(agentoo7.actor(np.array([state])).numpy())\n","        next_state, reward, done, _ = env.step(action)\n","        state = next_state\n","        total_reward += reward\n","\n","    return total_reward"],"metadata":{"id":"FdDH34HUA45f","executionInfo":{"status":"ok","timestamp":1674936984301,"user_tz":300,"elapsed":138,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def preprocess1(states, actions, rewards, done, values, gamma):\n","    g = 0\n","    lmbda = 0.95\n","    returns = []\n","    for i in reversed(range(len(rewards))):\n","        delta = rewards[i] + gamma * values[i + 1] * done[i] - values[i]\n","        g = delta + gamma * lmbda * dones[i] * g\n","        returns.append(g + values[i])\n","\n","    returns.reverse()\n","    adv = np.array(returns, dtype=np.float32) - values[:-1]\n","    adv = (adv - np.mean(adv)) / (np.std(adv) + 1e-10)\n","    states = np.array(states, dtype=np.float32)\n","    actions = np.array(actions, dtype=np.int32)\n","    returns = np.array(returns, dtype=np.float32)\n","\n","    return states, actions, returns, adv    "],"metadata":{"id":"70Hl3RsXA8gd","executionInfo":{"status":"ok","timestamp":1674936985743,"user_tz":300,"elapsed":137,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["### Define and Run Training"],"metadata":{"id":"mnwj-IYm_wHi"}},{"cell_type":"code","source":["tf.random.set_seed(2023)\n","agentoo7 = agent()\n","steps = 10000\n","ep_reward = []\n","total_avgr = []\n","target = False \n","best_reward = 0\n","avg_rewards_list = []\n","for s in range(steps):\n","    print(f'START: Running step = {s} now =====================================')\n","    if target == True:\n","        break\n","\n","    done = False\n","    state = env.reset()\n","    all_aloss = []\n","    all_closs = []\n","    rewards = []\n","    states = []\n","    actions = []\n","    probs = []\n","    dones = []\n","    values = []\n","    print(\"new episod\")\n","\n","    for e in range(128):\n","        action = agentoo7.act(state)\n","        value = agentoo7.critic(np.array([state])).numpy()\n","        next_state, reward, done, _ = env.step(action)\n","        dones.append(1-done)\n","        rewards.append(reward)\n","        states.append(state)\n","        #actions.append(tf.one_hot(action, 2, dtype=tf.int32).numpy().tolist())\n","        actions.append(action)\n","        prob = agentoo7.actor(np.array([state]))\n","        probs.append(prob[0])\n","        values.append(value[0][0])\n","        state = next_state\n","        if done:\n","            env.reset()\n","\n","    value = agentoo7.critic(np.array([state])).numpy()\n","    values.append(value[0][0])\n","    np.reshape(probs, (len(probs),2))\n","    probs = np.stack(probs, axis=0)\n","\n","    states, actions,returns, adv  = preprocess1(states, actions, rewards, dones, values, 1)\n","\n","    for epocs in range(10):\n","        al,cl = agentoo7.learn(states, actions, adv, probs, returns)\n","        # print(f\"al{al}\") \n","        # print(f\"cl{cl}\")\n","\n","    avg_reward = np.mean([test_reward(env) for _ in range(5)])\n","    print(f\"total test reward is {avg_reward}\")\n","    avg_rewards_list.append(avg_reward)\n","    if avg_reward > best_reward:\n","        print('best reward=' + str(avg_reward))\n","        agentoo7.actor.save('model_actor_{}_{}'.format(s, avg_reward), save_format=\"tf\")\n","        agentoo7.critic.save('model_critic_{}_{}'.format(s, avg_reward), save_format=\"tf\")\n","        best_reward = avg_reward\n","    if best_reward == 200:\n","        target = True\n","\n","    print(f'===================================== step {s} finished!')\n","    env.reset()\n","\n","env.close()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ybfQbu-s56sR","executionInfo":{"status":"ok","timestamp":1674937933293,"user_tz":300,"elapsed":49959,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"7ca406bf-bcac-4c17-bc1d-6c487f19dff9"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["START: Running step = 0 now =====================================\n","new episod\n","total test reward is 107.4\n","best reward=107.4\n","===================================== step 0 finished!\n","START: Running step = 1 now =====================================\n","new episod\n","total test reward is 62.0\n","===================================== step 1 finished!\n","START: Running step = 2 now =====================================\n","new episod\n","total test reward is 98.2\n","===================================== step 2 finished!\n","START: Running step = 3 now =====================================\n","new episod\n","total test reward is 49.2\n","===================================== step 3 finished!\n","START: Running step = 4 now =====================================\n","new episod\n","total test reward is 129.0\n","best reward=129.0\n","===================================== step 4 finished!\n","START: Running step = 5 now =====================================\n","new episod\n","total test reward is 116.0\n","===================================== step 5 finished!\n","START: Running step = 6 now =====================================\n","new episod\n","total test reward is 110.4\n","===================================== step 6 finished!\n","START: Running step = 7 now =====================================\n","new episod\n","total test reward is 174.8\n","best reward=174.8\n","===================================== step 7 finished!\n","START: Running step = 8 now =====================================\n","new episod\n","total test reward is 145.8\n","===================================== step 8 finished!\n","START: Running step = 9 now =====================================\n","new episod\n","total test reward is 135.4\n","===================================== step 9 finished!\n","START: Running step = 10 now =====================================\n","new episod\n","total test reward is 185.4\n","best reward=185.4\n","===================================== step 10 finished!\n","START: Running step = 11 now =====================================\n","new episod\n","total test reward is 200.0\n","best reward=200.0\n","===================================== step 11 finished!\n","START: Running step = 12 now =====================================\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt"],"metadata":{"id":"RtAsoiNg7XnF","executionInfo":{"status":"ok","timestamp":1674937462977,"user_tz":300,"elapsed":12,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["ep = [i  for i in range(len(avg_rewards_list))]\n","plt.plot( range(len(avg_rewards_list)),avg_rewards_list,'b')\n","plt.title(\"Avg Test Aeward Vs Test Episods\")\n","plt.xlabel(\"Test Episods\")\n","plt.ylabel(\"Average Test Reward\")\n","plt.grid(True)\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"LyXfrsBhDWT2","executionInfo":{"status":"ok","timestamp":1674937466261,"user_tz":300,"elapsed":536,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"b4c2e7e2-894a-4305-852f-3d1ad757d4c5"},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":[],"metadata":{"id":"NvacW5lmDXpR"},"execution_count":null,"outputs":[]}]}