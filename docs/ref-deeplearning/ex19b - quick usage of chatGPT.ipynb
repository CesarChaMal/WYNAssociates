{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI and ChatGPT\n",
        "\n",
        "This tutorial we walk through the usage of chatGPT. The goal is to use API to create quick chatGPT function to allow input and display the output. For tutorial, please watch my video on [Intro to ChatGPT](https://youtu.be/-y82RHZZmhI).\n",
        "\n",
        "![image](https://openai.com/content/images/2022/05/twitter-1.png)"
      ],
      "metadata": {
        "id": "UKwXP0CyGJ6J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the OpenAI API client. You can do this by running the following command: \n",
        "\n",
        "```py\n",
        "pip install openai\n",
        "```"
      ],
      "metadata": {
        "id": "l3HSoCMREASX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzY46oPdBvz5",
        "outputId": "b9ff38d8-1fee-4c81-bfad-bd439d04ffb5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.26.5.tar.gz (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 KB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.25.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (3.0.1)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.26.5-py3-none-any.whl size=67620 sha256=b38be88b2d18abd2938629188f077f60fabc74c1c9eb2ffd0f5680738607c85d\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/47/99/8273a59fbd59c303e8ff175416d5c1c9c03a2e83ebf7525a99\n",
            "Successfully built openai\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.26.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use this API: `<ENTER_API_HERE>`"
      ],
      "metadata": {
        "id": "MejTf6fcEO3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import\n",
        "import openai"
      ],
      "metadata": {
        "id": "vOGSekumBxAJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the API key\n",
        "openai.api_key = \"<ENTER_API_HERE>\""
      ],
      "metadata": {
        "id": "a2YHSOD4ETE0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the ChatGPT model to generate text\n",
        "model_engine = \"text-davinci-002\""
      ],
      "metadata": {
        "id": "obs4SAaMEVnn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define\n",
        "def chatGPT_machine(\n",
        "    prompt: str,\n",
        "    verbal: bool) -> dict:\n",
        "    completion = openai.Completion.create(\n",
        "        engine=model_engine,\n",
        "        prompt=prompt,\n",
        "        max_tokens=1024,\n",
        "        n=1,\n",
        "        stop=None,\n",
        "        temperature=0.7)\n",
        "    message = completion.choices[0].text\n",
        "    if verbal:\n",
        "        print(message)\n",
        "    \n",
        "    return {\n",
        "        \"complete_outcome\": completion,\n",
        "        \"message\": message\n",
        "    }"
      ],
      "metadata": {
        "id": "2uFJQZTzEZO9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run\n",
        "outcome = chatGPT_machine(\"write a poem using jay z's lyrics\", True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdapBZ_NFtwI",
        "outputId": "55d39da0-5c77-48cc-af01-6c1b591b4d2c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "I got 99 problems but a bitch ain't one\n",
            "I got the rap game sewn up, put a stitch in it\n",
            "I'm cold-hearted, sold my soul for a profit\n",
            "I know it sounds evil but hey, what's up?\n",
            "I got 99 problems but a bitch ain't one\n",
            "I got the rap game sewn up, put a stitch in it\n",
            "I'm cold-hearted, sold my soul for a profit\n",
            "I know it sounds evil but hey, what's up?\n",
            "\n",
            "I got 99 problems but a bitch ain't one\n",
            "I got the rap game sewn up, put a stitch in it\n",
            "I'm cold-hearted, sold my soul for a profit\n",
            "I know it sounds evil but hey, what's up?\n",
            "\n",
            "I got 99 problems but a bitch ain't one\n",
            "I got the rap game sewn up, put a stitch in it\n",
            "I'm cold-hearted, sold my soul for a profit\n",
            "I know it sounds evil but hey, what's up?\n",
            "\n",
            "I got 99 problems but a bitch ain't one\n",
            "I got the rap game sewn up, put a stitch in it\n",
            "I'm cold-hearted, sold my soul for a profit\n",
            "I know it sounds evil but hey, what's up?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run\n",
        "outcome = chatGPT_machine(\"write a neural network function with one dense layer using tensorflow\", True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9XD4fbqF3kk",
        "outputId": "d70166f1-bf32-4ee3-8f6e-5a28ad8ab0ba"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "def dense_layer(x, n_neurons, activation=None):\n",
            "    n_inputs = int(x.get_shape()[1])\n",
            "    stddev = 2 / np.sqrt(n_inputs)\n",
            "    init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
            "    W = tf.Variable(init, name=\"weights\")\n",
            "    b = tf.Variable(tf.zeros([n_neurons]), name=\"biases\")\n",
            "    z = tf.matmul(x, W) + b\n",
            "    if activation==\"relu\":\n",
            "        return tf.nn.relu(z)\n",
            "    else:\n",
            "        return z\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run\n",
        "outcome = chatGPT_machine(\"what is reinforcement learning?\", True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVSId5MIF_N3",
        "outputId": "4f614173-030e-4406-b083-871e84480f9c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Reinforcement learning is a computational approach to learning where an agent tries to maximize some notion of cumulative reward by choosing the best action at each step, given its current state.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run\n",
        "outcome = chatGPT_machine(\"create a terraform for aws to deploy a lambda function\", True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMEEE2ENE34j",
        "outputId": "5ae5d14e-5169-4777-9135-08f700cd2119"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "resource \"aws_lambda_function\" \"my_lambda_function\" {\n",
            "  filename         = \"my_lambda_function.zip\"\n",
            "  function_name    = \"my_lambda_function\"\n",
            "  role             = \"${aws_iam_role.lambda_exec_role.arn}\"\n",
            "  handler          = \"my_lambda_function.handler\"\n",
            "  runtime          = \"python3.7\"\n",
            "  environment {\n",
            "    variables = {\n",
            "      MY_VARIABLE = \"my_value\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "resource \"aws_iam_role\" \"lambda_exec_role\" {\n",
            "  name = \"lambda_exec_role\"\n",
            "\n",
            "  assume_role_policy = <<EOF\n",
            "{\n",
            "  \"Version\": \"2012-10-17\",\n",
            "  \"Statement\": [\n",
            "    {\n",
            "      \"Action\": \"sts:AssumeRole\",\n",
            "      \"Principal\": {\n",
            "        \"Service\": \"lambda.amazonaws.com\"\n",
            "      },\n",
            "      \"Effect\": \"Allow\",\n",
            "      \"Sid\": \"\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "EOF\n",
            "}\n",
            "\n",
            "resource \"aws_iam_role_policy_attachment\" \"lambda_exec_role_policy_attachment\" {\n",
            "  role       = \"${aws_iam_role.lambda_exec_role.name}\"\n",
            " policy_arn = \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AcKxL-YbE7Dn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}