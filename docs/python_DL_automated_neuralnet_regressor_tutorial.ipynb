{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# W.Y.N. Education: Tutorial for Automated Neural Network Regressor\n",
        "\n"
      ],
      "metadata": {
        "id": "2kSN8M-eSP-7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is Neural Network?\n",
        "\n",
        "Artificial neural networks (ANNs), usually simply called neural networks (NNs), are computing systems inspired by the biological neural networks that constitute animal brains.\n",
        "\n",
        "An ANN is based on a collection of connected units or nodes called artificial neurons, which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit a signal to other neurons. An artificial neuron receives a signal then processes it and can signal neurons connected to it. The \"signal\" at a connection is a real number, and the output of each neuron is computed by some non-linear function of the sum of its inputs. The connections are called edges. Neurons and edges typically have a weight that adjusts as learning proceeds. The weight increases or decreases the strength of the signal at a connection. Neurons may have a threshold such that a signal is sent only if the aggregate signal crosses that threshold. Typically, neurons are aggregated into layers. Different layers may perform different transformations on their inputs. Signals travel from the first layer (the input layer), to the last layer (the output layer), possibly after traversing the layers multiple times.\n",
        "\n"
      ],
      "metadata": {
        "id": "sX9L51iaVVYc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network Architecture?\n",
        "\n",
        "![image](https://upload.wikimedia.org/wikipedia/commons/4/46/Colored_neural_network.svg)\n",
        "\n"
      ],
      "metadata": {
        "id": "PA2W6lX7VYiR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Artificial neurons\n",
        "\n",
        "ANNs are composed of artificial neurons which are conceptually derived from biological neurons. Each artificial neuron has inputs and produces a single output which can be sent to multiple other neurons.The inputs can be the feature values of a sample of external data, such as images or documents, or they can be the outputs of other neurons. The outputs of the final output neurons of the neural net accomplish the task, such as recognizing an object in an image.\n",
        "\n",
        "To find the output of the neuron, First we must take the weighted sum of all the inputs, weighted by the weights of the connections from the inputs to the neuron. We add a bias term to this sum. This weighted sum is sometimes called the activation. This weighted sum is then passed through a (usually nonlinear) activation function to produce the output. The initial inputs are external data, such as images and documents. The ultimate outputs accomplish the task, such as recognizing an object in an image.\n",
        "\n"
      ],
      "metadata": {
        "id": "GxwUwfMPVZpa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Organization\n",
        "\n",
        "The neurons are typically organized into multiple layers, especially in deep learning. Neurons of one layer connect only to neurons of the immediately preceding and immediately following layers. The layer that receives external data is the input layer. The layer that produces the ultimate result is the output layer. In between them are zero or more hidden layers. Single layer and unlayered networks are also used. Between two layers, multiple connection patterns are possible. They can be 'fully connected', with every neuron in one layer connecting to every neuron in the next layer. They can be pooling, where a group of neurons in one layer connect to a single neuron in the next layer, thereby reducing the number of neurons in that layer. Neurons with only such connections form a directed acyclic graph and are known as feedforward networks. Alternatively, networks that allow connections between neurons in the same or previous layers are known as recurrent networks.\n",
        "\n"
      ],
      "metadata": {
        "id": "U2-cDLpWVbPI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Learning\n",
        "\n",
        "Learning is the adaptation of the network to better handle a task by considering sample observations. Learning involves adjusting the weights (and optional thresholds) of the network to improve the accuracy of the result. This is done by minimizing the observed errors. Learning is complete when examining additional observations does not usefully reduce the error rate. Even after learning, the error rate typically does not reach 0. If after learning, the error rate is too high, the network typically must be redesigned. Practically this is done by defining a cost function that is evaluated periodically during learning. As long as its output continues to decline, learning continues. The cost is frequently defined as a statistic whose value can only be approximated. The outputs are actually numbers, so when the error is low, the difference between the output (almost certainly a cat) and the correct answer (cat) is small. Learning attempts to reduce the total of the differences across the observations. Most learning models can be viewed as a straightforward application of optimization theory and statistical estimation.\n",
        "\n"
      ],
      "metadata": {
        "id": "qSX8gBezVcOL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Supervised learning\n",
        "\n",
        "Supervised learning uses a set of paired inputs and desired outputs. The learning task is to produce the desired output for each input. In this case the cost function is related to eliminating incorrect deductions. A commonly used cost is the mean-squared error, which tries to minimize the average squared error between the network's output and the desired output. Tasks suited for supervised learning are pattern recognition (also known as classification) and regression (also known as function approximation). Supervised learning is also applicable to sequential data (e.g., for hand writing, speech and gesture recognition). This can be thought of as learning with a \"teacher\", in the form of a function that provides continuous feedback on the quality of solutions obtained thus far.\n",
        "\n"
      ],
      "metadata": {
        "id": "l0BeKkaRVdi5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification vs Regression\n",
        "\n",
        "Classification predictive modeling problems are different from regression predictive modeling problems.\n",
        "\n",
        "Classification is the task of predicting a discrete class label.\n",
        "Regression is the task of predicting a continuous quantity.\n",
        "\n",
        "This notebook focuses on regression problems so the tutorial walks readers through a regressor machine."
      ],
      "metadata": {
        "id": "svxHYdVKV1jb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Software\n",
        "\n",
        "TensorFlow is a free and open-source software library for machine learning and artificial intelligence. It can be used across a range of tasks but has a particular focus on training and inference of deep neural networks.\n",
        "\n",
        "TensorFlow was developed by the Google Brain team for internal Google use in research and production. The initial version was released under the Apache License 2.0 in 2015. Google released the updated version of TensorFlow, named TensorFlow 2.0, in September 2019.\n",
        "\n",
        "The production code in this software is developed and automated using Tensorflow and Keras."
      ],
      "metadata": {
        "id": "Qbt4HNB5VeZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/yiqiao-yin/WYNAssociates.git # in jupyter notebook"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IW6xN_QFEkRk",
        "outputId": "d443656c-b66d-4322-886e-2b9669d3d599"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/yiqiao-yin/WYNAssociates.git\n",
            "  Cloning https://github.com/yiqiao-yin/WYNAssociates.git to /tmp/pip-req-build-9batrudv\n",
            "  Running command git clone -q https://github.com/yiqiao-yin/WYNAssociates.git /tmp/pip-req-build-9batrudv\n",
            "Building wheels for collected packages: WYNAssociates\n",
            "  Building wheel for WYNAssociates (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for WYNAssociates: filename=WYNAssociates-1.0.0-py3-none-any.whl size=18742 sha256=e10c56446113e97e7b3f992b71ceb86fa3d080628288be1b7d56b54ede1b062e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-24pffrr2/wheels/e7/8d/cb/5eaa7fa9db48dbabd76f0c5e07ad4946ca059ecfaa79e94c49\n",
            "Successfully built WYNAssociates\n",
            "Installing collected packages: WYNAssociates\n",
            "Successfully installed WYNAssociates-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yfinance ta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-afAQsnTHp1a",
        "outputId": "83851df2-a03e-412e-c2cf-56cc0c5ef88f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.70-py2.py3-none-any.whl (26 kB)\n",
            "Collecting ta\n",
            "  Downloading ta-0.9.0.tar.gz (25 kB)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Collecting lxml>=4.5.1\n",
            "  Downloading lxml-4.7.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 12.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.19.5)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.10)\n",
            "Collecting requests>=2.26\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.0.11)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Building wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.9.0-py3-none-any.whl size=28908 sha256=b007e301bb0947793a6ba3ddb162494304f5637d42e9897de313fab162356cd2\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/78/64/cc1c01506a1010a9845e9bd7c69333730f7174661228ea4f98\n",
            "Successfully built ta\n",
            "Installing collected packages: requests, lxml, yfinance, ta\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed lxml-4.7.1 requests-2.27.1 ta-0.9.0 yfinance-0.1.70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Library"
      ],
      "metadata": {
        "id": "9QIR4O84WC9A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oyEI4YEtmEKk"
      },
      "outputs": [],
      "source": [
        "# library\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "hxrcBm_VWEib"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YqsjOJdWmJi3"
      },
      "outputs": [],
      "source": [
        "# data\n",
        "housing = fetch_california_housing()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BzbIqwlOmL3V"
      },
      "outputs": [],
      "source": [
        "# train, validate, and test\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "v06KxjWDmM9G"
      },
      "outputs": [],
      "source": [
        "# standardize\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train) # What is training set?\n",
        "X_valid = scaler.transform(X_valid) # What is validating set?\n",
        "X_test = scaler.transform(X_test) # What is test set?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjeLmuSBnGtr",
        "outputId": "0b0440f7-e468-46aa-c1ba-3009c797c71b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11610, 8)\n",
            "(3870, 8)\n",
            "(5160, 8)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(X_valid.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load WYN Software"
      ],
      "metadata": {
        "id": "KZRBYxtSWGkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from AI_solution.modules import YinsDL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aex-1u13EybP",
        "outputId": "e40821d5-ebd5-4cc9-9c1d-1f2eaecb5da3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------\n",
            "\n",
            "        Yin's Deep Learning Package \n",
            "        Copyright © W.Y.N. Associates, LLC, 2009 – Present\n",
            "        For more information, please go to www.YinsCapital.com\n",
            "        \n",
            "---------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = YinsDL.NeuralNet_Regressor(\n",
        "    X_train=X_train, \n",
        "    y_train=y_train, \n",
        "    X_valid=X_valid, \n",
        "    y_valid=y_valid, \n",
        "    X_test=X_test, \n",
        "    y_test=y_test,\n",
        "    input_shape=[8],\n",
        "    hidden=[1024*2, 1024, 512, 256, 128, 128, 64, 32],\n",
        "    output_shape=1,\n",
        "    activation=\"relu\",\n",
        "    learning_rate=0.0001,\n",
        "    loss=\"mse\",\n",
        "    epochs=10,\n",
        "    useGPU=True,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arfnFXkGcWon",
        "outputId": "5366d5ed-68b8-497a-c32c-9fdc11f21edb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 2048)              18432     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,832,513\n",
            "Trainable params: 2,832,513\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Found GPU at: /device:GPU:0\n",
            "Using GPU to compute...\n",
            "Epoch 1/10\n",
            "363/363 [==============================] - 7s 7ms/step - loss: 4.8413 - val_loss: 4.1218\n",
            "Epoch 2/10\n",
            "363/363 [==============================] - 3s 7ms/step - loss: 3.4501 - val_loss: 2.8565\n",
            "Epoch 3/10\n",
            "363/363 [==============================] - 2s 7ms/step - loss: 2.3397 - val_loss: 1.9112\n",
            "Epoch 4/10\n",
            "363/363 [==============================] - 2s 6ms/step - loss: 1.6229 - val_loss: 1.4142\n",
            "Epoch 5/10\n",
            "363/363 [==============================] - 2s 6ms/step - loss: 1.3141 - val_loss: 1.2385\n",
            "Epoch 6/10\n",
            "363/363 [==============================] - 2s 6ms/step - loss: 1.2033 - val_loss: 1.1622\n",
            "Epoch 7/10\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 1.1338 - val_loss: 1.0981\n",
            "Epoch 8/10\n",
            "363/363 [==============================] - 3s 7ms/step - loss: 1.0661 - val_loss: 1.0329\n",
            "Epoch 9/10\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.9964 - val_loss: 0.9657\n",
            "Epoch 10/10\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.9261 - val_loss: 0.8988\n",
            "Training time consumption 26.75089168548584 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp['Test Result']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BoxJrqeWZ4A",
        "outputId": "f3a656a5-1987-489e-da49-3e856474a6a6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'RMSE_test': 0.9468634662124606,\n",
              " 'y_test_hat_': array([1.8576801, 1.9684055, 2.1525443, ..., 1.9366105, 1.719464 ,\n",
              "        2.046873 ], dtype=float32)}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "python_DL_automated_neuralnet_regressor_tutorial.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}