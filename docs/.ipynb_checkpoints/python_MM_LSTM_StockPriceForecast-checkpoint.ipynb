{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Money Management: Stock Price Forecasting Using Long Short Term Memory (LSTM)\n",
    "\n",
    "LSTM is an tweak version of Recurrent Neural Network which forgets or remembers certain information over a long period of time. In this notebook, I will use LSTM to forecast Google stock price.\n",
    "\n",
    "Stock price today is probably dependent on:\n",
    "- The trend it has been folloing from the previous day.\n",
    "- The price it was traded at from previous day.\n",
    "- Some other factors that may affect stock price today.\n",
    "\n",
    "Generalize intuition from above to the following:\n",
    "- The previous cell state (i.e. the information that was present in the memory after the previous time step).\n",
    "- The previous hidden state (i.e. this is the same as the output of the previous cell).\n",
    "- The input at the current time step (i.e. the new information that is being fed in at that moment).\n",
    "\n",
    "In this notebook, we cover\n",
    "- Part 1 - Data Preprocessing\n",
    "- Part 2 - Construct RNN Architecture\n",
    "- Part 3 - Predictions and Performance Visualization\n",
    "\n",
    "Source: see [Chapter 11](https://github.com/PacktPublishing/Hands-on-Python-for-Finance/tree/master/Chapter%2011) of **Hands on Python for Finance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network (a sequential model)\n",
    "\n",
    "Given data $X$ and $Y$, we want to feed information forward into a time stamp. Then we form some belief and we make some initial predictions. We investigate our beliefs by looking at the loss function of the initial guesses and the real value. We update our model according to error we observed. \n",
    "\n",
    "## Architecture: Feed-forward\n",
    "\n",
    "Consider data with time stamp\n",
    "$$X_{\\langle 1 \\rangle} \\rightarrow X_{\\langle 2 \\rangle} \\rightarrow \\dots \\rightarrow X_{\\langle T \\rangle}$$\n",
    "and feed-forward architecture pass information through exactly as the following:\n",
    "$$\n",
    "\\text{Information in:} \\rightarrow\n",
    "\\begin{matrix}\n",
    "Y_{\\langle 1 \\rangle}, \\hat{Y}_{\\langle 1 \\rangle} & Y_{\\langle 2 \\rangle}, \\hat{Y}_{\\langle 2 \\rangle} &       & Y_{\\langle T \\rangle}, \\hat{Y}_{\\langle T \\rangle} \\\\\n",
    "\\uparrow               & \\uparrow               &       & \\uparrow \\\\\n",
    "X_{\\langle 1 \\rangle} \\rightarrow    & X_{\\langle 2 \\rangle} \\rightarrow    & \\dots \\rightarrow & X_{\\langle T \\rangle} \\\\\n",
    "\\uparrow               & \\uparrow               &       & \\uparrow \\\\\n",
    "w_{\\langle 1 \\rangle}, b_{0, \\langle 1 \\rangle}    & w_{\\langle 2 \\rangle}, b_{0, \\langle 2 \\rangle}    &       & w_{\\langle T \\rangle}, b_{0, \\langle T \\rangle} \\\\\n",
    "\\end{matrix}\n",
    "\\rightarrow\n",
    "\\text{Form beliefs about } Y_{\\angle T \\rangle}\n",
    "$$\n",
    "while the educated guesses $\\hat{Y}_{\\langle T \\rangle}$ are our beliefs about real $Y$ at time stamp $T$. \n",
    "\n",
    "## Architecture: Feed-backward\n",
    "\n",
    "Let us clearly define our loss function to make sure we have a proper grip of our mistakes. \n",
    "$$\\mathcal{L} = \\sum_t L(\\hat{y}_{\\langle t \\rangle} - y_t)^2$$\n",
    "and we can compute the gradient \n",
    "$$\\triangledown = \\frac{\\partial \\mathcal{L}}{\\partial a}$$\n",
    "and then with respect with parameters $w$ and $b$\n",
    "$$\\frac{\\partial \\triangledown}{\\partial w}, \\frac{\\partial \\triangledown}{\\partial a}$$\n",
    "and now with perspective of where we make our mistakes according to our parameters we can go backward\n",
    "$$\n",
    "\\text{Information in:} \\leftarrow\n",
    "\\underbrace{\n",
    "\\begin{matrix}\n",
    "Y_{\\langle 1 \\rangle}, \\hat{Y}_{\\langle 1 \\rangle} & Y_{\\langle 2 \\rangle}, \\hat{Y}_{\\langle 2 \\rangle} &       & Y_{\\langle T \\rangle}, \\hat{Y}_{\\langle T \\rangle} \\\\\n",
    "\\uparrow               & \\uparrow               &       & \\uparrow \\\\\n",
    "X_{\\langle 1 \\rangle} \\leftarrow    & X_{\\langle 2 \\rangle} \\leftarrow    & \\dots \\leftarrow & X_{\\langle T \\rangle} \\\\\n",
    "\\uparrow               & \\uparrow               &       & \\uparrow \\\\\n",
    "w'_{\\langle 1 \\rangle}, b'_{0, \\langle 1 \\rangle}    & w'_{\\langle 2 \\rangle}, b'_{0, \\langle 2 \\rangle}    &       & w'_{\\langle T \\rangle}, b'_{0, \\langle T \\rangle} \\\\\n",
    "\\end{matrix}}_{\\text{Update: } w, b \\text{ with } w', b'}\n",
    "\\leftarrow\n",
    "\\text{Total Loss: } \\mathcal{L} (\\hat{y}, y)\n",
    "$$\n",
    "and the *update* action in the above architecture is dependent on your optimizer specified in the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 - Data Preprocessing\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "#!pip install yfinance\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "ticker = \"AAPL\"\n",
    "dataset_train = yf.download(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-07-09</th>\n",
       "      <td>142.750000</td>\n",
       "      <td>145.649994</td>\n",
       "      <td>142.649994</td>\n",
       "      <td>145.110001</td>\n",
       "      <td>145.110001</td>\n",
       "      <td>99788400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-12</th>\n",
       "      <td>146.210007</td>\n",
       "      <td>146.320007</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.500000</td>\n",
       "      <td>144.500000</td>\n",
       "      <td>76299700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-13</th>\n",
       "      <td>144.029999</td>\n",
       "      <td>147.460007</td>\n",
       "      <td>143.630005</td>\n",
       "      <td>145.639999</td>\n",
       "      <td>145.639999</td>\n",
       "      <td>100698900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-14</th>\n",
       "      <td>148.100006</td>\n",
       "      <td>149.570007</td>\n",
       "      <td>147.679993</td>\n",
       "      <td>149.149994</td>\n",
       "      <td>149.149994</td>\n",
       "      <td>126871000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-15</th>\n",
       "      <td>149.240005</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>147.095001</td>\n",
       "      <td>147.490005</td>\n",
       "      <td>147.490005</td>\n",
       "      <td>81435318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2021-07-09  142.750000  145.649994  142.649994  145.110001  145.110001   \n",
       "2021-07-12  146.210007  146.320007  144.000000  144.500000  144.500000   \n",
       "2021-07-13  144.029999  147.460007  143.630005  145.639999  145.639999   \n",
       "2021-07-14  148.100006  149.570007  147.679993  149.149994  149.149994   \n",
       "2021-07-15  149.240005  150.000000  147.095001  147.490005  147.490005   \n",
       "\n",
       "               Volume  \n",
       "Date                   \n",
       "2021-07-09   99788400  \n",
       "2021-07-12   76299700  \n",
       "2021-07-13  100698900  \n",
       "2021-07-14  126871000  \n",
       "2021-07-15   81435318  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Open      High       Low     Close  Adj Close     Volume\n",
      "Date                                                                    \n",
      "1980-12-12  0.128348  0.128906  0.128348  0.128348   0.100751  469033600\n",
      "1980-12-15  0.122210  0.122210  0.121652  0.121652   0.095495  175884800\n",
      "1980-12-16  0.113281  0.113281  0.112723  0.112723   0.088485  105728000\n",
      "1980-12-17  0.115513  0.116071  0.115513  0.115513   0.090676   86441600\n",
      "1980-12-18  0.118862  0.119420  0.118862  0.118862   0.093304   73449600\n",
      "                  Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "2021-07-09  142.750000  145.649994  142.649994  145.110001  145.110001   \n",
      "2021-07-12  146.210007  146.320007  144.000000  144.500000  144.500000   \n",
      "2021-07-13  144.029999  147.460007  143.630005  145.639999  145.639999   \n",
      "2021-07-14  148.100006  149.570007  147.679993  149.149994  149.149994   \n",
      "2021-07-15  149.240005  150.000000  147.095001  147.490005  147.490005   \n",
      "\n",
      "               Volume  \n",
      "Date                   \n",
      "2021-07-09   99788400  \n",
      "2021-07-12   76299700  \n",
      "2021-07-13  100698900  \n",
      "2021-07-14  126871000  \n",
      "2021-07-15   81435318  \n"
     ]
    }
   ],
   "source": [
    "# Preview\n",
    "print(dataset_train.head())\n",
    "print(dataset_train.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.28905997e-01]\n",
      " [1.22210003e-01]\n",
      " [1.13280997e-01]\n",
      " ...\n",
      " [1.47460007e+02]\n",
      " [1.49570007e+02]\n",
      " [1.50000000e+02]]\n"
     ]
    }
   ],
   "source": [
    "# Select Open Column\n",
    "training_set = dataset_train.iloc[:, 1:2].values\n",
    "print(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.28448278e-04],\n",
       "       [4.83793538e-04],\n",
       "       [4.24247111e-04],\n",
       "       ...,\n",
       "       [9.83061103e-01],\n",
       "       [9.97132433e-01],\n",
       "       [1.00000000e+00]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a data structure with 100 timesteps and 1 output. 1258 is the total number of records in the Open column\n",
    "for i in range(100, 1258):\n",
    "    X_train.append(training_set_scaled[i-100:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1158, 100)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1158,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1158, 100, 1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - Building RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RNN\n",
    "regressor = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the RNN to the Training set\n",
    "regressor.fit(X_train, y_train, epochs = 20, batch_size = 64)\n",
    "# Comment:\n",
    "# Originally, the batch_size was set 32 in the ipynb provided by the authors.\n",
    "# I changed it to 64. This is because I believe for Google a sequence of 32 is not enough.\n",
    "# My intuition is confirmed. If you use 32, you will observe a larger test error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 - Making the predictions and visualising the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train.iloc[10000::,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3 - Making the predictions and visualising the results\n",
    "\n",
    "# Getting the real stock price of later years\n",
    "dataset_test = dataset_train.iloc[10000::,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_stock_price = dataset_test.iloc[:, 1:2].values\n",
    "\n",
    "# Getting the predicted stock price of 2017\n",
    "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0)\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 100:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs = sc.transform(inputs)\n",
    "X_test = []\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100, 330):\n",
    "    X_test.append(inputs[i-100:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_stock_price = regressor.predict(X_test)\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_stock_price[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_stock_price = abs(predicted_stock_price) * 190"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_stock_price[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the results\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(real_stock_price, color = 'red', label = 'Real ' + ticker + ' Stock Price')\n",
    "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted ' + ticker + ' Stock Price')\n",
    "plt.title(ticker + ' Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel(ticker + ' Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_stock_price.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_stock_price.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(real_stock_price[~np.isnan(real_stock_price)], predicted_stock_price[~np.isnan(real_stock_price)]))\n",
    "print(f'Root Mean Square Error is {round(rmse,2)} for test set.')\n",
    "print(f'Interpretation: ---------------')\n",
    "print(f'On the test set, the performance of this LSTM architecture guesses Google stock price \\non average within the error of ${round(rmse,2)} dollars.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
